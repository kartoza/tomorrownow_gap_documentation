{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Documentation","text":""},{"location":"#tomorrow-now-gap","title":"Tomorrow Now GAP","text":""},{"location":"#overview","title":"Overview","text":""},{"location":"#key-concepts","title":"Key Concepts","text":""},{"location":"#disclaimer","title":"Disclaimer","text":"The software provided by this project is provided 'as is'. All information provided  within the platform should be independently verified before using as the basis for action. The contributors and developers of this platform take no responsibility for any loss of revenue, life, physical harm or any other adverse outcome that may  occur as a result of the use of this platform."},{"location":"#releases","title":"Releases","text":"<p>Our releases are published on our GitHub releases page</p> Project Badges"},{"location":"#project-chatroom","title":"Project Chatroom","text":"<p>We do not yet have a Chatroom set up for this project. Please use the GitHub issue tracker for discussions rather.</p>"},{"location":"#contributor-license-agreement-cla","title":"Contributor License Agreement (CLA)","text":"<p>Contributions to this project will be subject to our Contributor License Agreement (Coming soon)</p>"},{"location":"#license","title":"License","text":"<p>This project is open source, published under the AGPL-3.  You can read our license to find out what rights this license bestows to users and contributors.</p> <p>License</p>"},{"location":"quick_installation/","title":"Quick installation","text":""},{"location":"quick_installation/#quick-installation","title":"Quick installation","text":""},{"location":"quick_installation/#production","title":"Production","text":"<pre><code>git submodule update\ngit clone https://github.com/kartoza/tomorrownow_gap\ncp deployment/.template.env deployment/.env\ncp deployment/docker-compose.override.template deployment/docker-compose.template\nmake up\n</code></pre> <p>The web will be available at <code>http://127.0.0.1/</code></p> <p>To stop containers:</p> <pre><code>make kill\n</code></pre> <p>To stop and delete containers:</p> <pre><code>make down\n</code></pre>"},{"location":"quick_installation/#development","title":"Development","text":"<pre><code>git submodule update\ngit clone https://github.com/kartoza/tomorrownow_gap\ncp deployment/.template.env deployment/.env\ncp deployment/docker-compose.override.template deployment/docker-compose.template\n</code></pre> <p>After that, do</p> <ul> <li>open new terminal</li> <li>on folder root of project, do</li> </ul> <pre><code>make serve\n</code></pre> <p>Wait until it is done when there is sentence \"webpack xxx compiled successfully in xxx ms\". After that, don't close the terminal. If it is accidentally closed, do <code>make serve</code> again</p> <p>Next step:</p> <ul> <li>Open new terminal</li> <li>Do commands below</li> </ul> <pre><code>make up\nmake dev\n</code></pre> <p>Wait until it is on.</p> <p>The web can be accessed using <code>http://localhost:5000/</code></p> <p>If the web is taking long time to load, restart tomorrownow_gap_dev_1 container. The sequence should be <code>make dev</code>, after that run or restart tomorrownow_gap_dev_1.</p>"},{"location":"about/","title":"TomorrowNow - Global Access Platform (GAP)","text":""},{"location":"about/#aboutnotarobot","title":"AboutNotARobot","text":""},{"location":"about/#license","title":"License","text":"<p>Published under AGPL-3. See the full license text.</p>"},{"location":"about/#contributors","title":"Contributors","text":"Contributor GitHub Handle Hugh Mann NotARobot Tim Sutton timlinux"},{"location":"about/#project-fundersbackers","title":"Project funders/backers","text":"<p>This project was conceptualized and initially funded by FUNDER_1.</p>"},{"location":"about/#logos","title":"Logos","text":"<p>Another fine project contributed to by: Kartoza.com </p>"},{"location":"about/code-of-conduct/","title":"TomorrowNow - Global Access Platform (GAP)","text":""},{"location":"about/code-of-conduct/#contributor-covenant-code-of-conduct","title":"Contributor covenant code of conduct","text":""},{"location":"about/code-of-conduct/#our-pledge","title":"Our pledge","text":"<p>In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p>"},{"location":"about/code-of-conduct/#our-standards","title":"Our standards","text":"<p>Examples of behaviour that contributes to creating a positive environment include:</p> <ul> <li>Using welcoming and inclusive language</li> <li>Being respectful of differing viewpoints and experiences</li> <li>Gracefully accepting constructive criticism</li> <li>Focusing on what is best for the community</li> <li>Showing empathy towards other community members</li> </ul> <p>Examples of unacceptable behaviour by participants include:</p> <ul> <li>The use of sexualized language or imagery and unwelcome sexual attention or   advances</li> <li>Trolling, insulting/derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or electronic   address, without explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a   professional setting</li> </ul>"},{"location":"about/code-of-conduct/#our-responsibilities","title":"Our responsibilities","text":"<p>Project maintainers are responsible for clarifying the standards of acceptable behaviour and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behaviour.</p> <p>Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.</p>"},{"location":"about/code-of-conduct/#scope","title":"Scope","text":"<p>This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.</p>"},{"location":"about/code-of-conduct/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behaviour may be reported by contacting the project team. All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident.  Further details of specific enforcement policies may be posted separately.</p> <p>Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.</p>"},{"location":"about/code-of-conduct/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html</p>"},{"location":"about/contributing/","title":"TomorrowNow - Global Access Platform (GAP)","text":""},{"location":"about/contributing/#contributing-to-project_name","title":"Contributing to [PROJECT_NAME]","text":"<p>First off, thanks for taking the time to contribute! \ud83c\udf89 \ud83d\ude18 \u2728</p> <p>The following is a set of guidelines for contributing to this project. These are mostly guidelines, not rules. Use your best judgment, and feel free to propose changes to this document in a pull request.</p>"},{"location":"about/contributing/#reporting-bugs","title":"Reporting bugs","text":"<p>Bugs are tracked as GitHub issues. Search the list and try reproduce on your local machine with a clean profile before you create an issue. When you create an issue, please provide the following information by filling in the template.</p> <p>Explain the problem and include additional details to help maintainers reproduce the problem:</p> <ul> <li>Use a clear and descriptive title for the issue to identify the problem.</li> <li>Describe the exact steps which reproduce the problem in as many details   as possible. Don't just say what you did, but explain how you did it. For   example, if you moved the cursor to the end of a line, explain if you used a   mouse or a keyboard.</li> <li>Provide specific examples to demonstrate the steps. Include links to   files or GitHub projects, or copy/paste-able snippets, which you use in those   examples. If you're providing snippets on the issue, use Markdown code blocks.</li> <li>Describe the behaviour you observed after following the steps and point   out what exactly is the problem with that behaviour.</li> <li>Explain which behaviour you expected to see instead and why.</li> <li>Include screenshots and animated GIFs which show you following the   described steps and clearly demonstrate the problem.</li> </ul>"},{"location":"about/contributing/#suggesting-enhancements","title":"Suggesting enhancements","text":"<p>In case you want to suggest an enhancement, please follow this guideline to help maintainers and the community understand your suggestion. Before creating suggestions, please check issue list if there's already a request.</p> <p>Create an issue and provide the following information:</p> <ul> <li>Use a clear and descriptive title for the issue to identify the   suggestion.</li> <li>Provide a step-by-step description of the suggested enhancement in as   many details as possible.</li> <li>Provide specific examples to demonstrate the steps. Include   copy/paste-able snippets which you use in those examples, as Markdown code   blocks.</li> <li>Include screenshots and animated GIFs which helps demonstrate the steps   or point out the part of project which the suggestion is related to.</li> <li>Explain why this enhancement would be useful to most users.</li> <li>List some other text editors or applications where this enhancement   exists.</li> </ul>"},{"location":"about/contributing/#first-code-contribution","title":"First code contribution","text":"<p>Unsure where to begin contributing? You can start by looking through these <code>document</code>, <code>good first issue</code> and <code>help wanted</code> issues:</p> <ul> <li>document issues: issues which should be reviewed or improved.</li> <li>good first issues: issues which should only require a few lines of code,   and a test or two.</li> <li>help wanted issues: issues which should be a bit more involved than   beginner issues.</li> </ul>"},{"location":"about/contributing/#pull-requests","title":"Pull requests","text":""},{"location":"about/contributing/#development-workflow","title":"Development workflow","text":"<ul> <li>Set up your development environment</li> <li>Make change from a right branch</li> <li>Be sure the code passes tests</li> <li>Make a pull request</li> </ul>"},{"location":"about/contributing/#development-environment","title":"Development environment","text":"<ul> <li>Prepare your machine and it's packages installed.</li> <li>Checkout our repository</li> <li>Install dependencies by <code>pip install -r REQUIREMENTS-dev.txt</code></li> </ul>"},{"location":"about/contributing/#make-changes","title":"Make changes","text":""},{"location":"about/contributing/#checkout-a-branch","title":"Checkout a branch","text":"<ul> <li>master: PR Base branch.</li> <li>production: lastest release branch with distribution files. Never make a PR on this.</li> <li>gh-pages: API docs, examples and demo</li> </ul>"},{"location":"about/contributing/#check-code-style","title":"Check code style","text":"<p>Run the pylance extension and make sure all the tests pass.</p>"},{"location":"about/contributing/#test","title":"Test","text":"<p>Run <code>TODO</code> and verify all the tests pass. If you are adding new commands or features, they must include tests. If you are changing functionality, update the tests if you need to.</p>"},{"location":"about/contributing/#commit","title":"Commit","text":"<p>Follow our commit message conventions.</p>"},{"location":"about/contributing/#yes-pull-request","title":"Yes! Pull request","text":"<p>Make your pull request, then describe your changes.</p>"},{"location":"about/contributing/#title","title":"Title","text":"<p>Follow other PR title format on below.</p> <pre><code>    &lt;Type&gt;: Short Description (fix #111)\n    &lt;Type&gt;: Short Description (fix #123, #111, #122)\n    &lt;Type&gt;: Short Description (ref #111)\n</code></pre> <ul> <li>capitalize first letter of Type</li> <li>use present tense: 'change' not 'changed' or 'changes'</li> </ul>"},{"location":"about/contributing/#description","title":"Description","text":"<p>If it has related issues, add links to the issues(like <code>#123</code>) in the description. Fill in the Pull Request Template by checking your case.</p>"},{"location":"about/contributing/#code-of-conduct","title":"Code of conduct","text":"<p>This project and everyone participating in it is governed by the Code of Conduct. By participating, you are expected to uphold this code. Please report unacceptable behaviour to tim@kartoza.com.</p> <p>This guide is based on atom contributing guide, CocoaPods and ESLint</p>"},{"location":"about/disclaimer/","title":"TomorrowNow - Global Access Platform (GAP)","text":""},{"location":"about/disclaimer/#disclaimer","title":"Disclaimer","text":"<p>Disclaimer about project.</p>"},{"location":"about/license/","title":"GNU Affero General Public License","text":""},{"location":"about/license/#gnu-affero-general-public-license","title":"GNU Affero General Public License","text":"<p>Version 3, 19 November 2007 Copyright \u00a9 2007 Free Software Foundation, Inc. &lt;http://fsf.org/&gt;</p> <p>Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed.</p>"},{"location":"about/license/#preamble","title":"Preamble","text":"<p>The GNU Affero General Public License is a free, copyleft license for software and other kinds of works, specifically designed to ensure cooperation with the community in the case of network server software.</p> <p>The licenses for most software and other practical works are designed to take away your freedom to share and change the works.  By contrast, our General Public Licenses are intended to guarantee your freedom to share and change all versions of a program--to make sure it remains free software for all its users.</p> <p>When we speak of free software, we are referring to freedom, not price.  Our General Public Licenses are designed to make sure that you have the freedom to distribute copies of free software (and charge for them if you wish), that you receive source code or can get it if you want it, that you can change the software or use pieces of it in new free programs, and that you know you can do these things.</p> <p>Developers that use our General Public Licenses protect your rights with two steps: (1) assert copyright on the software, and (2) offer you this License which gives you legal permission to copy, distribute and/or modify the software.</p> <p>A secondary benefit of defending all users' freedom is that improvements made in alternate versions of the program, if they receive widespread use, become available for other developers to incorporate.  Many developers of free software are heartened and encouraged by the resulting cooperation.  However, in the case of software used on network servers, this result may fail to come about. The GNU General Public License permits making a modified version and letting the public access it on a server without ever releasing its source code to the public.</p> <p>The GNU Affero General Public License is designed specifically to ensure that, in such cases, the modified source code becomes available to the community.  It requires the operator of a network server to provide the source code of the modified version running there to the users of that server.  Therefore, public use of a modified version, on a publicly accessible server, gives the public access to the source code of the modified version.</p> <p>An older license, called the Affero General Public License and published by Affero, was designed to accomplish similar goals.  This is a different license, not a version of the Affero GPL, but Affero has released a new version of the Affero GPL which permits relicensing under this license.</p> <p>The precise terms and conditions for copying, distribution and modification follow.</p>"},{"location":"about/license/#terms-and-conditions","title":"TERMS AND CONDITIONS","text":""},{"location":"about/license/#0-definitions","title":"0. Definitions","text":"<p>\u201cThis License\u201d refers to version 3 of the GNU Affero General Public License.</p> <p>\u201cCopyright\u201d also means copyright-like laws that apply to other kinds of works, such as semiconductor masks.</p> <p>\u201cThe Program\u201d refers to any copyrightable work licensed under this License.  Each licensee is addressed as \u201cyou\u201d.  \u201cLicensees\u201d and \u201crecipients\u201d may be individuals or organizations.</p> <p>To \u201cmodify\u201d a work means to copy from or adapt all or part of the work in a fashion requiring copyright permission, other than the making of an exact copy.  The resulting work is called a \u201cmodified version\u201d of the earlier work or a work \u201cbased on\u201d the earlier work.</p> <p>A \u201ccovered work\u201d means either the unmodified Program or a work based on the Program.</p> <p>To \u201cpropagate\u201d a work means to do anything with it that, without permission, would make you directly or secondarily liable for infringement under applicable copyright law, except executing it on a computer or modifying a private copy.  Propagation includes copying, distribution (with or without modification), making available to the public, and in some countries other activities as well.</p> <p>To \u201cconvey\u201d a work means any kind of propagation that enables other parties to make or receive copies.  Mere interaction with a user through a computer network, with no transfer of a copy, is not conveying.</p> <p>An interactive user interface displays \u201cAppropriate Legal Notices\u201d to the extent that it includes a convenient and prominently visible feature that (1) displays an appropriate copyright notice, and (2) tells the user that there is no warranty for the work (except to the extent that warranties are provided), that licensees may convey the work under this License, and how to view a copy of this License.  If the interface presents a list of user commands or options, such as a menu, a prominent item in the list meets this criterion.</p>"},{"location":"about/license/#1-source-code","title":"1. Source Code","text":"<p>The \u201csource code\u201d for a work means the preferred form of the work for making modifications to it.  \u201cObject code\u201d means any non-source form of a work.</p> <p>A \u201cStandard Interface\u201d means an interface that either is an official standard defined by a recognized standards body, or, in the case of interfaces specified for a particular programming language, one that is widely used among developers working in that language.</p> <p>The \u201cSystem Libraries\u201d of an executable work include anything, other than the work as a whole, that (a) is included in the normal form of packaging a Major Component, but which is not part of that Major Component, and (b) serves only to enable use of the work with that Major Component, or to implement a Standard Interface for which an implementation is available to the public in source code form.  A \u201cMajor Component\u201d, in this context, means a major essential component (kernel, window system, and so on) of the specific operating system (if any) on which the executable work runs, or a compiler used to produce the work, or an object code interpreter used to run it.</p> <p>The \u201cCorresponding Source\u201d for a work in object code form means all the source code needed to generate, install, and (for an executable work) run the object code and to modify the work, including scripts to control those activities.  However, it does not include the work's System Libraries, or general-purpose tools or generally available free programs which are used unmodified in performing those activities but which are not part of the work.  For example, Corresponding Source includes interface definition files associated with source files for the work, and the source code for shared libraries and dynamically linked subprograms that the work is specifically designed to require, such as by intimate data communication or control flow between those subprograms and other parts of the work.</p> <p>The Corresponding Source need not include anything that users can regenerate automatically from other parts of the Corresponding Source.</p> <p>The Corresponding Source for a work in source code form is that same work.</p>"},{"location":"about/license/#2-basic-permissions","title":"2. Basic Permissions","text":"<p>All rights granted under this License are granted for the term of copyright on the Program, and are irrevocable provided the stated conditions are met.  This License explicitly affirms your unlimited permission to run the unmodified Program.  The output from running a covered work is covered by this License only if the output, given its content, constitutes a covered work.  This License acknowledges your rights of fair use or other equivalent, as provided by copyright law.</p> <p>You may make, run and propagate covered works that you do not convey, without conditions so long as your license otherwise remains in force.  You may convey covered works to others for the sole purpose of having them make modifications exclusively for you, or provide you with facilities for running those works, provided that you comply with the terms of this License in conveying all material for which you do not control copyright.  Those thus making or running the covered works for you must do so exclusively on your behalf, under your direction and control, on terms that prohibit them from making any copies of your copyrighted material outside their relationship with you.</p> <p>Conveying under any other circumstances is permitted solely under the conditions stated below.  Sublicensing is not allowed; section 10 makes it unnecessary.</p>"},{"location":"about/license/#3-protecting-users-legal-rights-from-anti-circumvention-law","title":"3. Protecting Users' Legal Rights From Anti-Circumvention Law","text":"<p>No covered work shall be deemed part of an effective technological measure under any applicable law fulfilling obligations under article 11 of the WIPO copyright treaty adopted on 20 December 1996, or similar laws prohibiting or restricting circumvention of such measures.</p> <p>When you convey a covered work, you waive any legal power to forbid circumvention of technological measures to the extent such circumvention is effected by exercising rights under this License with respect to the covered work, and you disclaim any intention to limit operation or modification of the work as a means of enforcing, against the work's users, your or third parties' legal rights to forbid circumvention of technological measures.</p>"},{"location":"about/license/#4-conveying-verbatim-copies","title":"4. Conveying Verbatim Copies","text":"<p>You may convey verbatim copies of the Program's source code as you receive it, in any medium, provided that you conspicuously and appropriately publish on each copy an appropriate copyright notice; keep intact all notices stating that this License and any non-permissive terms added in accord with section 7 apply to the code; keep intact all notices of the absence of any warranty; and give all recipients a copy of this License along with the Program.</p> <p>You may charge any price or no price for each copy that you convey, and you may offer support or warranty protection for a fee.</p>"},{"location":"about/license/#5-conveying-modified-source-versions","title":"5. Conveying Modified Source Versions","text":"<p>You may convey a work based on the Program, or the modifications to produce it from the Program, in the form of source code under the terms of section 4, provided that you also meet all of these conditions:</p> <ul> <li>a) The work must carry prominent notices stating that you modified it, and giving a relevant date.</li> <li>b) The work must carry prominent notices stating that it is released under this License and any conditions added under section 7. This requirement modifies the requirement in section 4 to \u201ckeep intact all notices\u201d.</li> <li>c) You must license the entire work, as a whole, under this License to anyone who comes into possession of a copy.  This License will therefore apply, along with any applicable section 7 additional terms, to the whole of the work, and all its parts, regardless of how they are packaged.  This License gives no permission to license the work in any other way, but it does not invalidate such permission if you have separately received it.</li> <li>d) If the work has interactive user interfaces, each must display Appropriate Legal Notices; however, if the Program has interactive interfaces that do not display Appropriate Legal Notices, your work need not make them do so.</li> </ul> <p>A compilation of a covered work with other separate and independent works, which are not by their nature extensions of the covered work, and which are not combined with it such as to form a larger program, in or on a volume of a storage or distribution medium, is called an \u201caggregate\u201d if the compilation and its resulting copyright are not used to limit the access or legal rights of the compilation's users beyond what the individual works permit.  Inclusion of a covered work in an aggregate does not cause this License to apply to the other parts of the aggregate.</p>"},{"location":"about/license/#6-conveying-non-source-forms","title":"6. Conveying Non-Source Forms","text":"<p>You may convey a covered work in object code form under the terms of sections 4 and 5, provided that you also convey the machine-readable Corresponding Source under the terms of this License, in one of these ways:</p> <ul> <li>a) Convey the object code in, or embodied in, a physical product (including a physical distribution medium), accompanied by the Corresponding Source fixed on a durable physical medium customarily used for software interchange.</li> <li>b) Convey the object code in, or embodied in, a physical product (including a physical distribution medium), accompanied by a written offer, valid for at least three years and valid for as long as you offer spare parts or customer support for that product model, to give anyone who possesses the object code either (1) a copy of the Corresponding Source for all the software in the product that is covered by this License, on a durable physical medium customarily used for software interchange, for a price no more than your reasonable cost of physically performing this conveying of source, or (2) access to copy the Corresponding Source from a network server at no charge.</li> <li>c) Convey individual copies of the object code with a copy of the written offer to provide the Corresponding Source.  This alternative is allowed only occasionally and noncommercially, and only if you received the object code with such an offer, in accord with subsection 6b.</li> <li>d) Convey the object code by offering access from a designated place (gratis or for a charge), and offer equivalent access to the Corresponding Source in the same way through the same place at no further charge.  You need not require recipients to copy the Corresponding Source along with the object code.  If the place to copy the object code is a network server, the Corresponding Source may be on a different server (operated by you or a third party) that supports equivalent copying facilities, provided you maintain clear directions next to the object code saying where to find the Corresponding Source.  Regardless of what server hosts the Corresponding Source, you remain obligated to ensure that it is available for as long as needed to satisfy these requirements.</li> <li>e) Convey the object code using peer-to-peer transmission, provided you inform other peers where the object code and Corresponding Source of the work are being offered to the general public at no charge under subsection 6d.</li> </ul> <p>A separable portion of the object code, whose source code is excluded from the Corresponding Source as a System Library, need not be included in conveying the object code work.</p> <p>A \u201cUser Product\u201d is either (1) a \u201cconsumer product\u201d, which means any tangible personal property which is normally used for personal, family, or household purposes, or (2) anything designed or sold for incorporation into a dwelling.  In determining whether a product is a consumer product, doubtful cases shall be resolved in favor of coverage.  For a particular product received by a particular user, \u201cnormally used\u201d refers to a typical or common use of that class of product, regardless of the status of the particular user or of the way in which the particular user actually uses, or expects or is expected to use, the product.  A product is a consumer product regardless of whether the product has substantial commercial, industrial or non-consumer uses, unless such uses represent the only significant mode of use of the product.</p> <p>\u201cInstallation Information\u201d for a User Product means any methods, procedures, authorization keys, or other information required to install and execute modified versions of a covered work in that User Product from a modified version of its Corresponding Source.  The information must suffice to ensure that the continued functioning of the modified object code is in no case prevented or interfered with solely because modification has been made.</p> <p>If you convey an object code work under this section in, or with, or specifically for use in, a User Product, and the conveying occurs as part of a transaction in which the right of possession and use of the User Product is transferred to the recipient in perpetuity or for a fixed term (regardless of how the transaction is characterized), the Corresponding Source conveyed under this section must be accompanied by the Installation Information.  But this requirement does not apply if neither you nor any third party retains the ability to install modified object code on the User Product (for example, the work has been installed in ROM).</p> <p>The requirement to provide Installation Information does not include a requirement to continue to provide support service, warranty, or updates for a work that has been modified or installed by the recipient, or for the User Product in which it has been modified or installed.  Access to a network may be denied when the modification itself materially and adversely affects the operation of the network or violates the rules and protocols for communication across the network.</p> <p>Corresponding Source conveyed, and Installation Information provided, in accord with this section must be in a format that is publicly documented (and with an implementation available to the public in source code form), and must require no special password or key for unpacking, reading or copying.</p>"},{"location":"about/license/#7-additional-terms","title":"7. Additional Terms","text":"<p>\u201cAdditional permissions\u201d are terms that supplement the terms of this License by making exceptions from one or more of its conditions. Additional permissions that are applicable to the entire Program shall be treated as though they were included in this License, to the extent that they are valid under applicable law.  If additional permissions apply only to part of the Program, that part may be used separately under those permissions, but the entire Program remains governed by this License without regard to the additional permissions.</p> <p>When you convey a copy of a covered work, you may at your option remove any additional permissions from that copy, or from any part of it.  (Additional permissions may be written to require their own removal in certain cases when you modify the work.)  You may place additional permissions on material, added by you to a covered work, for which you have or can give appropriate copyright permission.</p> <p>Notwithstanding any other provision of this License, for material you add to a covered work, you may (if authorized by the copyright holders of that material) supplement the terms of this License with terms:</p> <ul> <li>a) Disclaiming warranty or limiting liability differently from the terms of sections 15 and 16 of this License; or</li> <li>b) Requiring preservation of specified reasonable legal notices or author attributions in that material or in the Appropriate Legal Notices displayed by works containing it; or</li> <li>c) Prohibiting misrepresentation of the origin of that material, or requiring that modified versions of such material be marked in reasonable ways as different from the original version; or</li> <li>d) Limiting the use for publicity purposes of names of licensors or authors of the material; or</li> <li>e) Declining to grant rights under trademark law for use of some trade names, trademarks, or service marks; or</li> <li>f) Requiring indemnification of licensors and authors of that material by anyone who conveys the material (or modified versions of it) with contractual assumptions of liability to the recipient, for any liability that these contractual assumptions directly impose on those licensors and authors.</li> </ul> <p>All other non-permissive additional terms are considered \u201cfurther restrictions\u201d within the meaning of section 10.  If the Program as you received it, or any part of it, contains a notice stating that it is governed by this License along with a term that is a further restriction, you may remove that term.  If a license document contains a further restriction but permits relicensing or conveying under this License, you may add to a covered work material governed by the terms of that license document, provided that the further restriction does not survive such relicensing or conveying.</p> <p>If you add terms to a covered work in accord with this section, you must place, in the relevant source files, a statement of the additional terms that apply to those files, or a notice indicating where to find the applicable terms.</p> <p>Additional terms, permissive or non-permissive, may be stated in the form of a separately written license, or stated as exceptions; the above requirements apply either way.</p>"},{"location":"about/license/#8-termination","title":"8. Termination","text":"<p>You may not propagate or modify a covered work except as expressly provided under this License.  Any attempt otherwise to propagate or modify it is void, and will automatically terminate your rights under this License (including any patent licenses granted under the third paragraph of section 11).</p> <p>However, if you cease all violation of this License, then your license from a particular copyright holder is reinstated (a) provisionally, unless and until the copyright holder explicitly and finally terminates your license, and (b) permanently, if the copyright holder fails to notify you of the violation by some reasonable means prior to 60 days after the cessation.</p> <p>Moreover, your license from a particular copyright holder is reinstated permanently if the copyright holder notifies you of the violation by some reasonable means, this is the first time you have received notice of violation of this License (for any work) from that copyright holder, and you cure the violation prior to 30 days after your receipt of the notice.</p> <p>Termination of your rights under this section does not terminate the licenses of parties who have received copies or rights from you under this License.  If your rights have been terminated and not permanently reinstated, you do not qualify to receive new licenses for the same material under section 10.</p>"},{"location":"about/license/#9-acceptance-not-required-for-having-copies","title":"9. Acceptance Not Required for Having Copies","text":"<p>You are not required to accept this License in order to receive or run a copy of the Program.  Ancillary propagation of a covered work occurring solely as a consequence of using peer-to-peer transmission to receive a copy likewise does not require acceptance.  However, nothing other than this License grants you permission to propagate or modify any covered work.  These actions infringe copyright if you do not accept this License.  Therefore, by modifying or propagating a covered work, you indicate your acceptance of this License to do so.</p>"},{"location":"about/license/#10-automatic-licensing-of-downstream-recipients","title":"10. Automatic Licensing of Downstream Recipients","text":"<p>Each time you convey a covered work, the recipient automatically receives a license from the original licensors, to run, modify and propagate that work, subject to this License.  You are not responsible for enforcing compliance by third parties with this License.</p> <p>An \u201centity transaction\u201d is a transaction transferring control of an organization, or substantially all assets of one, or subdividing an organization, or merging organizations.  If propagation of a covered work results from an entity transaction, each party to that transaction who receives a copy of the work also receives whatever licenses to the work the party's predecessor in interest had or could give under the previous paragraph, plus a right to possession of the Corresponding Source of the work from the predecessor in interest, if the predecessor has it or can get it with reasonable efforts.</p> <p>You may not impose any further restrictions on the exercise of the rights granted or affirmed under this License.  For example, you may not impose a license fee, royalty, or other charge for exercise of rights granted under this License, and you may not initiate litigation (including a cross-claim or counterclaim in a lawsuit) alleging that any patent claim is infringed by making, using, selling, offering for sale, or importing the Program or any portion of it.</p>"},{"location":"about/license/#11-patents","title":"11. Patents","text":"<p>A \u201ccontributor\u201d is a copyright holder who authorizes use under this License of the Program or a work on which the Program is based.  The work thus licensed is called the contributor's \u201ccontributor version\u201d.</p> <p>A contributor's \u201cessential patent claims\u201d are all patent claims owned or controlled by the contributor, whether already acquired or hereafter acquired, that would be infringed by some manner, permitted by this License, of making, using, or selling its contributor version, but do not include claims that would be infringed only as a consequence of further modification of the contributor version.  For purposes of this definition, \u201ccontrol\u201d includes the right to grant patent sublicenses in a manner consistent with the requirements of this License.</p> <p>Each contributor grants you a non-exclusive, worldwide, royalty-free patent license under the contributor's essential patent claims, to make, use, sell, offer for sale, import and otherwise run, modify and propagate the contents of its contributor version.</p> <p>In the following three paragraphs, a \u201cpatent license\u201d is any express agreement or commitment, however denominated, not to enforce a patent (such as an express permission to practice a patent or covenant not to sue for patent infringement).  To \u201cgrant\u201d such a patent license to a party means to make such an agreement or commitment not to enforce a patent against the party.</p> <p>If you convey a covered work, knowingly relying on a patent license, and the Corresponding Source of the work is not available for anyone to copy, free of charge and under the terms of this License, through a publicly available network server or other readily accessible means, then you must either (1) cause the Corresponding Source to be so available, or (2) arrange to deprive yourself of the benefit of the patent license for this particular work, or (3) arrange, in a manner consistent with the requirements of this License, to extend the patent license to downstream recipients.  \u201cKnowingly relying\u201d means you have actual knowledge that, but for the patent license, your conveying the covered work in a country, or your recipient's use of the covered work in a country, would infringe one or more identifiable patents in that country that you have reason to believe are valid.</p> <p>If, pursuant to or in connection with a single transaction or arrangement, you convey, or propagate by procuring conveyance of, a covered work, and grant a patent license to some of the parties receiving the covered work authorizing them to use, propagate, modify or convey a specific copy of the covered work, then the patent license you grant is automatically extended to all recipients of the covered work and works based on it.</p> <p>A patent license is \u201cdiscriminatory\u201d if it does not include within the scope of its coverage, prohibits the exercise of, or is conditioned on the non-exercise of one or more of the rights that are specifically granted under this License.  You may not convey a covered work if you are a party to an arrangement with a third party that is in the business of distributing software, under which you make payment to the third party based on the extent of your activity of conveying the work, and under which the third party grants, to any of the parties who would receive the covered work from you, a discriminatory patent license (a) in connection with copies of the covered work conveyed by you (or copies made from those copies), or (b) primarily for and in connection with specific products or compilations that contain the covered work, unless you entered into that arrangement, or that patent license was granted, prior to 28 March 2007.</p> <p>Nothing in this License shall be construed as excluding or limiting any implied license or other defenses to infringement that may otherwise be available to you under applicable patent law.</p>"},{"location":"about/license/#12-no-surrender-of-others-freedom","title":"12. No Surrender of Others' Freedom","text":"<p>If conditions are imposed on you (whether by court order, agreement or otherwise) that contradict the conditions of this License, they do not excuse you from the conditions of this License.  If you cannot convey a covered work so as to satisfy simultaneously your obligations under this License and any other pertinent obligations, then as a consequence you may not convey it at all.  For example, if you agree to terms that obligate you to collect a royalty for further conveying from those to whom you convey the Program, the only way you could satisfy both those terms and this License would be to refrain entirely from conveying the Program.</p>"},{"location":"about/license/#13-remote-network-interaction-use-with-the-gnu-general-public-license","title":"13. Remote Network Interaction; Use with the GNU General Public License","text":"<p>Notwithstanding any other provision of this License, if you modify the Program, your modified version must prominently offer all users interacting with it remotely through a computer network (if your version supports such interaction) an opportunity to receive the Corresponding Source of your version by providing access to the Corresponding Source from a network server at no charge, through some standard or customary means of facilitating copying of software.  This Corresponding Source shall include the Corresponding Source for any work covered by version 3 of the GNU General Public License that is incorporated pursuant to the following paragraph.</p> <p>Notwithstanding any other provision of this License, you have permission to link or combine any covered work with a work licensed under version 3 of the GNU General Public License into a single combined work, and to convey the resulting work.  The terms of this License will continue to apply to the part which is the covered work, but the work with which it is combined will remain governed by version 3 of the GNU General Public License.</p>"},{"location":"about/license/#14-revised-versions-of-this-license","title":"14. Revised Versions of this License","text":"<p>The Free Software Foundation may publish revised and/or new versions of the GNU Affero General Public License from time to time.  Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns.</p> <p>Each version is given a distinguishing version number.  If the Program specifies that a certain numbered version of the GNU Affero General Public License \u201cor any later version\u201d applies to it, you have the option of following the terms and conditions either of that numbered version or of any later version published by the Free Software Foundation.  If the Program does not specify a version number of the GNU Affero General Public License, you may choose any version ever published by the Free Software Foundation.</p> <p>If the Program specifies that a proxy can decide which future versions of the GNU Affero General Public License can be used, that proxy's public statement of acceptance of a version permanently authorizes you to choose that version for the Program.</p> <p>Later license versions may give you additional or different permissions.  However, no additional obligations are imposed on any author or copyright holder as a result of your choosing to follow a later version.</p>"},{"location":"about/license/#15-disclaimer-of-warranty","title":"15. Disclaimer of Warranty","text":"<p>THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \u201cAS IS\u201d WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION.</p>"},{"location":"about/license/#16-limitation-of-liability","title":"16. Limitation of Liability","text":"<p>IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.</p>"},{"location":"about/license/#17-interpretation-of-sections-15-and-16","title":"17. Interpretation of Sections 15 and 16","text":"<p>If the disclaimer of warranty and limitation of liability provided above cannot be given local legal effect according to their terms, reviewing courts shall apply local law that most closely approximates an absolute waiver of all civil liability in connection with the Program, unless a warranty or assumption of liability accompanies a copy of the Program in return for a fee.</p> <p>END OF TERMS AND CONDITIONS</p>"},{"location":"about/license/#how-to-apply-these-terms-to-your-new-programs","title":"How to Apply These Terms to Your New Programs","text":"<p>If you develop a new program, and you want it to be of the greatest possible use to the public, the best way to achieve this is to make it free software which everyone can redistribute and change under these terms.</p> <p>To do so, attach the following notices to the program.  It is safest to attach them to the start of each source file to most effectively state the exclusion of warranty; and each file should have at least the \u201ccopyright\u201d line and a pointer to where the full notice is found.</p> <pre><code>&lt;one line to give the program's name and a brief idea of what it does.&gt;\nCopyright (C) &lt;year&gt;  &lt;name of author&gt;\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Affero General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU Affero General Public License for more details.\n\nYou should have received a copy of the GNU Affero General Public License\nalong with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.\n</code></pre> <p>Also add information on how to contact you by electronic and paper mail.</p> <p>If your software can interact with users remotely through a computer network, you should also make sure that it provides a way for users to get its source.  For example, if your program is a web application, its interface could display a \u201cSource\u201d link that leads users to an archive of the code.  There are many ways you could offer source, and different solutions will be better for different programs; see section 13 for the specific requirements.</p> <p>You should also get your employer (if you work as a programmer) or school, if any, to sign a \u201ccopyright disclaimer\u201d for the program, if necessary. For more information on this, and how to apply and follow the GNU AGPL, see &lt;http://www.gnu.org/licenses/&gt;.</p>"},{"location":"about/running-instances/","title":"Examples of running instances","text":""},{"location":"administrator/","title":"TomorrowNow - Global Access Platform (GAP)","text":""},{"location":"administrator/#for-administrators","title":"For administrators","text":"<p>This is the homepage for all administrator related documentation.</p> <p>The content is divided into two sections:</p> <ul> <li> <p>The user guide, which describes common workflows for system administrators in a tutorial format.</p> </li> <li> <p>The user manual, which describes each page of the admin user interface and what the various options on that page do.</p> </li> </ul>"},{"location":"administrator/guide/","title":"TomorrowNow - Global Access Platform (GAP)","text":""},{"location":"administrator/guide/#administrator-guide","title":"Administrator Guide","text":"<p>Welcome to the administrator guide. In this section of the documentation, we aim to show administrators common workflows for managing the platform effectively. Here is a brief overview of the content provided here:</p> <ul> <li>Accessing the Administration Panel: This section contains a quick description on how administrators can access the administration site of the platform.</li> </ul>"},{"location":"administrator/guide/access-admin-panel/","title":"Access Admin Panel","text":""},{"location":"administrator/guide/access-admin-panel/#accessing-the-django-admin-panel","title":"Accessing the Django Admin Panel","text":"<p>To access the Django admin panel, follow these steps:</p> <ol> <li>Access the Bash of the Django Container First, you need to access the bash of the container running Django.</li> </ol> <p>List Running Containers:</p> <p>Use the following command to view the running containers:</p> <p><code>docker ps</code></p> <p>This command displays a list of running containers. Locate and copy the name of the container running the Django image.</p> <p></p> <ol> <li>Access the Container's Bash:</li> </ol> <p>Run the following command to open a bash session in the container:</p> <p><code>docker exec -it &lt;Container Name&gt; bash</code></p> <p>Replace &lt;'Container Name'&gt; with the name of your Django container. For example:</p> <p><code>docker exec -it tomorrownow_gap-dev-1 bash</code></p> <p></p> <ol> <li>Create a Django Superuser</li> </ol> <p>Within the container\u2019s bash session, create a Django superuser by running:</p> <p><code>python manage.py createsuperuser</code></p> <p>You will be prompted to enter the following details:</p> <ul> <li>Username</li> <li>Email address</li> <li>Password</li> </ul> <p></p> <ol> <li>Log in to the Django Admin Panel:</li> </ol> <p>Once the superuser is created, you can access the Django admin panel through the web browser. Open your web browser and navigate to the following URL:</p> <p>http://yourhost/admin/</p> <p>For Example:</p> <p>http://localhost:8000/admin/</p> <p>Enter your username and password that you set up earlier, then click the 1\ufe0f\u20e3 <code>Login</code> button, to access the admin panel.</p> <p></p> <p>After login you will see the admin panel.</p> <p></p>"},{"location":"administrator/manual/","title":"TomorrowNow - Global Access Platform (GAP)","text":""},{"location":"administrator/manual/#administrator-manual","title":"Administrator Manual","text":"<p>Welcome to the TOMORROW.NOW administrator manual. This section of the documentation describes every administrator page in the application and what the various components of that page do. Here is a brief overview of the content provided here:</p> <ul> <li> <p>Django Administration: this section explains the django administration of the site.</p> </li> <li> <p>Django Tables: this section explains the django tables on the Django administration the site.</p> </li> <li> <p>Add Record in Taable: this section explains the addition of record on the Django administration site.</p> </li> <li> <p>Edit Record in Table: this section explains the editing of data on the Django administration the site.</p> </li> <li> <p>Monitor Background Task: this section explains how to monitor background task.</p> </li> </ul>"},{"location":"administrator/manual/django-add-record/","title":"TomorrowNow - Global Access Platform (GAP)","text":""},{"location":"administrator/manual/django-add-record/#add-record-to-the-table","title":"Add record to the table","text":""},{"location":"administrator/manual/django-add-record/#add-user","title":"Add User","text":"<p>The administrators will be presented with a form to enter the user's information. Here are the fields to fill in:</p> <ol> <li> <p>Username: Administrators should enter a unique username for the new user. It should be 150 characters, or less, and may contain only letters, digits, and the characters '@', '.', '+', '-', and '_'.</p> </li> <li> <p>Password: Administrators should create a strong password for the user. </p> </li> <li> <p>Password Confirmation: Administrators should re-enter the same password for verification.</p> </li> <li> <p>Save: Save the current record, then redirect to the Django Admin Table/record list.</p> </li> <li> <p>Save and add another: Save the current record, then redirect to a new page to add a new record.</p> </li> <li> <p>Save and continue editing: Save the current record while still showing the current record.</p> </li> </ol>"},{"location":"administrator/manual/django-add-record/#add-r-model-record","title":"Add R Model Record","text":"<p>Form Fields: Researchers have the ability to create a new R Model record by filling out the form fields. The following fields are available for input:</p> <ul> <li>Name: A unique identifier for the R Model.</li> <li>Version: The version number of the R Model.</li> <li>Code: The R code used to produce plant/no plant signals.</li> <li> <p>Notes: Additional comments or notes about the R Model.</p> </li> <li> <p>Created On: The date and time the R Model was created. Researchers can select the date from the calendar or set it to the current date by clicking on the <code>Today</code> button. The time can be set by clicking on the clock icon or set to the current time by clicking on the <code>Now</code> button.</p> </li> <li> <p>Created By: A dropdown menu listing the available researchers who can create R Models.</p> </li> <li> <p>Updated On: The date and time the R Model was last updated. Researchers can select the date from the calendar or set it to the current date by clicking on the <code>Today</code> button. The time can be set by clicking on the clock icon or set to the current time by clicking on the <code>Now</code> button.</p> </li> <li> <p>Updated By: A dropdown menu listing the available researchers who can update R Models.</p> </li> </ul> <p></p> <p>Fill all the required fields to save the r model record otherwise it will throw an error.</p> <p></p> <ol> <li> <p>R MODEL OUTPUTS: Click on the dropdown to select the type and enter the name into the variable name field.</p> </li> <li> <p>Save: This option saves the new R Model record and redirects administrators to the Django Admin Table/record list.</p> </li> <li> <p>Save and Add Another: This option saves the new R Model record and redirects administrators to a new page to add another R Model record.</p> </li> <li> <p>Save and Continue Editing: Choosing this option saves the new R Model record while still displaying the current record for further editing.</p> </li> </ol> <p>By following these steps, researchers can efficiently create and manage R Model records within the GAP Admin interface.</p>"},{"location":"administrator/manual/django-add-record/#add-auth-token","title":"Add Auth Token","text":"<ol> <li> <p>User: Select the user from the available users for whom you want to create an authentication token.</p> </li> <li> <p>Save: This option saves the new Auth Token record and redirects administrators to the Django Admin Table/record list.</p> </li> <li> <p>Save and Add Another: This option saves the new Auth Token record and redirects administrators to a new page to add another Auth Model record.</p> </li> </ol> <p>The process of creating the authentication token is completed.</p>"},{"location":"administrator/manual/django-admin/","title":"TomorrowNow - Global Access Platform (GAP)","text":""},{"location":"administrator/manual/django-admin/#django-admin-page-documentation","title":"Django Admin Page Documentation","text":"<p>The Django Admin is the central hub to create, read, update, or delete TOMORROW.NOW application data. Only users with staff status (i.e. administrators) can enter the administration page.</p>"},{"location":"administrator/manual/django-change-record/","title":"TomorrowNow - Global Access Platform (GAP)","text":""},{"location":"administrator/manual/django-change-record/#change-record","title":"Change Record","text":""},{"location":"administrator/manual/django-change-record/#change-user","title":"Change User","text":"<ol> <li> <p>History: Button to view actions applied to the current record.</p> </li> <li> <p>Change Password: The administrators can change the user's password by clicking on <code>this form</code> link. A popup will open to change the user's password.</p> <ul> <li> <p></p> </li> <li> <p>Change Password Form: Form to change the user's password.</p> </li> <li> <p>Change Password Button: The administrators can change the user's password by clicking on the <code>CHANGE PASSWORD</code> button.</p> </li> </ul> </li> <li> <p>Personal Information: The administrators can add/update the personal information of the user.</p> </li> </ol>"},{"location":"administrator/manual/django-change-record/#change-user-permission","title":"Change User Permission","text":"<ol> <li> <p>Checkbox: The administrators can grant permissions to a user by checking the checkbox.</p> </li> <li> <p>Arrows: The administrators can assign or unassign a group to the user by selecting and using these arrows.</p> </li> <li> <p>Choose All: The administrators can assign all available groups to the user.</p> </li> <li> <p>Remove All: The administrators can unassign all groups from the user.</p> </li> <li> <p>Permissions: The administrators can assign or unassign permissions to the user using this table.</p> </li> <li> <p>Search Permissions: The administrators can search for permissions using the search functionality.</p> </li> </ol>"},{"location":"administrator/manual/django-change-record/#change-dates-and-user-info","title":"Change Dates And User Info","text":"<ol> <li> <p>Dates: The administrators can edit the last login date-time and date joined date-time of a user from this section.</p> </li> <li> <p>Save: Save the current record, then redirect to the Django Admin Table/record list.</p> </li> <li> <p>Save and add another: Save the current record, then redirect to a new page to add a new record.</p> </li> <li> <p>Save and continue editing: Save the current record while still showing the current record.</p> </li> <li> <p>Delete: The administrators can delete the user by clicking on this button. The popup will open for the confirmation to delete the user.</p> </li> </ol>"},{"location":"administrator/manual/django-change-record/#change-r-model","title":"Change R Model","text":"<ol> <li> <p>History: Button to view actions applied to the current record.</p> </li> <li> <p>Form Fields: Researchers have the ability to update the values of various fields within the R Model form. The following fields are available for editing:</p> </li> <li> <p>Name</p> </li> <li>Version</li> <li>Code</li> <li>Notes</li> </ol> <p></p> <ul> <li> <p>Created On: The date and time the R Model was created. Researchers can select the date from the calendar or set it to the current date by clicking on the <code>Today</code> button. The time can be set by clicking on the clock icon or set to the current time by clicking on the <code>Now</code> button.</p> </li> <li> <p>Created By: A dropdown menu listing the available researchers who can create R Models.</p> </li> <li> <p>Updated On: The date and time the R Model was last updated. Researchers can select the date from the calendar or set it to the current date by clicking on the <code>Today</code> button. The time can be set by clicking on the clock icon or set to the current time by clicking on the <code>Now</code> button.</p> </li> <li> <p>Updated By: A dropdown menu listing the available researchers who can update R Models.</p> </li> <li> <p>Delete Checkbox: Check mark the checkbox to delete the associated r model outputs.</p> </li> <li> <p>Save: This option saves the current r model record and redirects administrators to the Django Admin Table/record list.</p> </li> <li> <p>Save and Add Another: This option saves the current rmodel record and redirects administrators to a new page to add another r model record.</p> </li> <li> <p>Save and Continue Editing: Choosing this option saves the current r model record while still displaying the current record for further editing.</p> </li> <li> <p>Delete: The administrator can delete the r model by clicking on the <code>Delete</code> button. It will ask for confirmation to delete the r model object.</p> <p></p> </li> </ul>"},{"location":"administrator/manual/django-change-record/#change-auth-token-model","title":"Change Auth Token Model","text":"<ol> <li> <p>History: Button to view actions applied to the current record.</p> </li> <li> <p>Save: Save the current record, then redirect to the Django Admin Table/record list.</p> </li> <li> <p>Save and add another: Save the current record, then redirect to a new page to add a new record.</p> </li> <li> <p>Save and continue editing: Save the current record while still showing the current record.</p> </li> <li> <p>Delete: The administrators can delete the user by clicking on this button. The popup will open for the confirmation to delete the user.</p> <p></p> <ol> <li> <p>Yes, I'm sure: Delete the current instance.</p> </li> <li> <p>No,take me back: Close the current popup window.</p> </li> </ol> </li> </ol>"},{"location":"administrator/manual/django-monitor-task/","title":"Monitor Background Task","text":""},{"location":"administrator/manual/django-monitor-task/#task-status-monitoring-system","title":"Task Status Monitoring System","text":""},{"location":"administrator/manual/django-monitor-task/#overview","title":"Overview","text":"<p>The Task Status Monitoring System provides automated monitoring of background Celery tasks and sends email notifications when tasks don't reach expected statuses within specified time windows. This helps administrators proactively detect and respond to task failures or delays.</p>"},{"location":"administrator/manual/django-monitor-task/#key-features","title":"Key Features","text":"<ul> <li>Automated Status Checking - Monitor multiple tasks with customizable status expectations</li> <li>Lookback Window - Configurable time window for checking task execution</li> <li>Email Notifications - HTML email alerts with detailed task information</li> <li>Dependent Task Warnings - Track and warn about downstream task impacts</li> <li>Flexible Recipients - Custom email lists or automatic superuser fallback</li> <li>Context Validation - Advanced filtering by task context type (e.g., specific ingestor types)</li> </ul>"},{"location":"administrator/manual/django-monitor-task/#configuration-format","title":"Configuration Format","text":"<p>The monitoring task accepts a configuration dictionary that maps task names to their monitoring settings:</p> <pre><code>{\n    \"task_name\": {\n        \"expected_statuses\": [\"Completed\"],           # Required\n        \"notify_to\": [\"admin@example.com\"],           # Optional\n        \"dependent_tasks\": [\"Task Y\", \"Task Z\"],      # Optional\n        \"lookback_hours\": 1,                          # Optional, default: 1\n        \"context_model\": \"gap.models.IngestorSession\", # Optional (advanced)\n        \"context_type\": \"Hourly Tomorrow.io\"          # Optional (advanced)\n    }\n}\n</code></pre>"},{"location":"administrator/manual/django-monitor-task/#configuration-parameters","title":"Configuration Parameters","text":"Parameter Type Required Default Description <code>expected_statuses</code> List[str] Yes - List of acceptable task statuses (e.g., <code>[\"Completed\"]</code>, <code>[\"Completed\", \"Running\"]</code>) <code>notify_to</code> List[str] No Superusers Email addresses to notify. If empty or not specified, notifications are sent to all superusers <code>dependent_tasks</code> List[str] No <code>[]</code> List of task names that depend on this task. Warnings are included in notification emails <code>lookback_hours</code> int/float No <code>1</code> Time window (in hours) to check for task execution. Can be integer or decimal (e.g., <code>1.5</code>) <code>context_model</code> str No - Model path for context validation (e.g., <code>\"gap.models.IngestorSession\"</code>) <code>context_type</code> str No - Expected context type for filtering (e.g., <code>\"Hourly Tomorrow.io\"</code>)"},{"location":"administrator/manual/django-monitor-task/#available-task-statuses","title":"Available Task Statuses","text":"<p>The following status values can be used in <code>expected_statuses</code>:</p> <ul> <li><code>Pending</code> - Task submitted but not queued</li> <li><code>Queued</code> - Task queued for execution</li> <li><code>Running</code> - Task currently executing</li> <li><code>Completed</code> - Task finished successfully</li> <li><code>Stopped</code> - Task stopped with error</li> <li><code>Cancelled</code> - Task was cancelled</li> <li><code>Invalidated</code> - Task was invalidated for retry</li> </ul> <p>Common configurations: - <code>[\"Completed\"]</code> - Only accept successful completion - <code>[\"Completed\", \"Running\"]</code> - Accept if completed or still running - <code>[\"Completed\", \"Stopped\"]</code> - Accept both success and failure (for monitoring only)</p>"},{"location":"administrator/manual/django-monitor-task/#lookback-hours-explanation","title":"Lookback Hours Explanation","text":"<p>The <code>lookback_hours</code> parameter defines the time window for checking task execution history. It determines how far back the system should look when searching for the most recent task execution.</p>"},{"location":"administrator/manual/django-monitor-task/#how-it-works","title":"How It Works","text":"<p>When a monitoring check runs: 1. Calculate the lookback threshold: <code>current_time - lookback_hours</code> 2. Query for the most recent task with <code>started_at &gt;= lookback_threshold</code> 3. Check if the status matches expected values 4. Send notification if no task found or status doesn't match</p>"},{"location":"administrator/manual/django-monitor-task/#choosing-appropriate-lookback-windows","title":"Choosing Appropriate Lookback Windows","text":"<p>Guidelines:</p> Task Frequency Recommended Lookback Example Every hour 1-2 hours Hourly data collection tasks Every 2 hours 2-3 hours Bi-hourly processing tasks Daily 24-25 hours Daily report generation Weekly 168-170 hours (7+ days) Weekly aggregation tasks <p>Best Practices:</p> <ol> <li>Make it slightly longer than task interval</li> <li>For a task expected every hour, use <code>lookback_hours: 1.5</code> or <code>2</code></li> <li> <p>This accommodates normal variations in task duration</p> </li> <li> <p>Account for delays</p> </li> <li>If tasks occasionally take longer, increase the window</li> <li> <p>Example: A task usually completes in 30 min but sometimes takes 2 hours \u2192 use <code>lookback_hours: 3</code></p> </li> <li> <p>Consider monitoring frequency</p> </li> <li>If you check every hour, lookback of 1 hour is usually sufficient</li> <li> <p>If you check less frequently, increase the lookback window proportionally</p> </li> <li> <p>Use decimal values for precision</p> </li> <li><code>lookback_hours: 1.5</code> checks last 1.5 hours (90 minutes)</li> <li>Useful for fine-tuning monitoring windows</li> </ol> <p>Examples:</p> <pre><code># Hourly task checked 5 minutes after expected completion\n{\n    \"hourly_data_sync\": {\n        \"expected_statuses\": [\"Completed\"],\n        \"lookback_hours\": 1  # Check last hour\n    }\n}\n\n# Daily task with variable duration\n{\n    \"daily_report\": {\n        \"expected_statuses\": [\"Completed\"],\n        \"lookback_hours\": 25  # Check last 25 hours (daily + buffer)\n    }\n}\n\n# Bi-hourly task with tolerance\n{\n    \"data_processing\": {\n        \"expected_statuses\": [\"Completed\", \"Running\"],\n        \"lookback_hours\": 2.5  # Check last 2.5 hours\n    }\n}\n</code></pre>"},{"location":"administrator/manual/django-monitor-task/#creating-periodic-tasks-via-django-admin","title":"Creating Periodic Tasks via Django Admin","text":""},{"location":"administrator/manual/django-monitor-task/#step-1-access-django-admin","title":"Step 1: Access Django Admin","text":"<p>Navigate to: Django Admin \u2192 Periodic Tasks \u2192 Add Periodic Task</p>"},{"location":"administrator/manual/django-monitor-task/#step-2-configure-basic-settings","title":"Step 2: Configure Basic Settings","text":"<p>Name: Give your monitoring task a descriptive name Example: <code>Monitor Critical Data Collection Tasks</code></p> <p>Task (registered): Type or select <code>monitor_task_status</code> Note: You may need to type this manually if it doesn't appear in the dropdown</p> <p>Enabled: \u2713 Check this box to activate monitoring</p>"},{"location":"administrator/manual/django-monitor-task/#step-3-configure-arguments","title":"Step 3: Configure Arguments","text":"<p>The <code>Arguments</code> field accepts JSON array with one dictionary containing your monitoring configuration:</p> <pre><code>[\n  {\n    \"task_name_1\": {\n      \"expected_statuses\": [\"Completed\"],\n      \"notify_to\": [\"admin@example.com\"],\n      \"dependent_tasks\": [\"task_name_2\"],\n      \"lookback_hours\": 1\n    },\n    \"task_name_2\": {\n      \"expected_statuses\": [\"Completed\"],\n      \"lookback_hours\": 2\n    }\n  }\n]\n</code></pre> <p>Important: The JSON must be an array containing a single dictionary (note the outer <code>[</code> and <code>]</code>).</p>"},{"location":"administrator/manual/django-monitor-task/#step-4-configure-schedule","title":"Step 4: Configure Schedule","text":"<p>Option A: Crontab Schedule</p> <p>Click \"Create new Crontab Schedule\" or select existing:</p> Example Crontab Description Every hour at :05 <code>5 * * * *</code> Runs at 00:05, 01:05, 02:05, etc. Every 2 hours at :05 <code>5 */2 * * *</code> Runs at 00:05, 02:05, 04:05, etc. Daily at 10:05 AM UTC <code>5 10 * * *</code> Runs once daily at 10:05 AM Every 30 minutes <code>*/30 * * * *</code> Runs at :00 and :30 every hour Monday at 9:00 AM <code>0 9 * * 1</code> Runs weekly on Monday <p>Option B: Interval Schedule</p> <p>For simpler intervals like \"every X minutes/hours\": - Every 30 minutes: Period=30, Unit=Minutes - Every 2 hours: Period=2, Unit=Hours</p>"},{"location":"administrator/manual/django-monitor-task/#step-5-save","title":"Step 5: Save","text":"<p>Click Save to activate the monitoring task.</p>"},{"location":"administrator/manual/django-monitor-task/#example-json-configurations","title":"Example JSON Configurations","text":""},{"location":"administrator/manual/django-monitor-task/#example-1-simple-hourly-task-monitoring","title":"Example 1: Simple Hourly Task Monitoring","text":"<p>Monitor a single hourly task, check 5 minutes after expected completion:</p> <pre><code>[\n  {\n    \"hourly_data_sync\": {\n      \"expected_statuses\": [\"Completed\"],\n      \"notify_to\": [\"data-team@example.com\"],\n      \"lookback_hours\": 1\n    }\n  }\n]\n</code></pre> <p>Crontab: <code>5 * * * *</code> (every hour at :05)</p>"},{"location":"administrator/manual/django-monitor-task/#example-2-multiple-tasks-with-dependencies","title":"Example 2: Multiple Tasks with Dependencies","text":"<p>Monitor a data pipeline with dependent tasks:</p> <pre><code>[\n  {\n    \"data_collection\": {\n      \"expected_statuses\": [\"Completed\"],\n      \"notify_to\": [\"ops@example.com\"],\n      \"dependent_tasks\": [\"data_processing\", \"data_export\"],\n      \"lookback_hours\": 1\n    },\n    \"data_processing\": {\n      \"expected_statuses\": [\"Completed\", \"Running\"],\n      \"dependent_tasks\": [\"data_export\"],\n      \"lookback_hours\": 2\n    },\n    \"data_export\": {\n      \"expected_statuses\": [\"Completed\"],\n      \"lookback_hours\": 3\n    }\n  }\n]\n</code></pre> <p>Crontab: <code>*/30 * * * *</code> (every 30 minutes)</p>"},{"location":"administrator/manual/django-monitor-task/#example-3-daily-tasks-with-fallback-to-superusers","title":"Example 3: Daily Tasks with Fallback to Superusers","text":"<p>Monitor daily tasks without specifying recipients (uses superusers):</p> <pre><code>[\n  {\n    \"daily_report_generation\": {\n      \"expected_statuses\": [\"Completed\"],\n      \"lookback_hours\": 25\n    },\n    \"daily_cleanup\": {\n      \"expected_statuses\": [\"Completed\"],\n      \"lookback_hours\": 24\n    }\n  }\n]\n</code></pre> <p>Crontab: <code>5 9 * * *</code> (daily at 9:05 AM UTC)</p>"},{"location":"administrator/manual/django-monitor-task/#example-4-ingestorsession-with-context-validation-advanced","title":"Example 4: IngestorSession with Context Validation (Advanced)","text":"<p>Monitor specific ingestor type execution:</p> <pre><code>[\n  {\n    \"ingestor_session\": {\n      \"context_model\": \"gap.models.IngestorSession\",\n      \"context_type\": \"Hourly Tomorrow.io\",\n      \"expected_statuses\": [\"Completed\"],\n      \"notify_to\": [\"weather-team@example.com\"],\n      \"dependent_tasks\": [\"forecast_processing\"],\n      \"lookback_hours\": 2\n    }\n  }\n]\n</code></pre> <p>Crontab: <code>5 */2 * * *</code> (every 2 hours at :05)</p>"},{"location":"administrator/manual/django-monitor-task/#notification-recipient-logic","title":"Notification Recipient Logic","text":"<p>The system determines email recipients using the following logic:</p>"},{"location":"administrator/manual/django-monitor-task/#priority-order","title":"Priority Order","text":"<ol> <li>Custom Recipients - If <code>notify_to</code> is specified and not empty</li> <li>Emails are sent to the specified addresses</li> <li> <p>Superusers are NOT included automatically</p> </li> <li> <p>Superuser Fallback - If <code>notify_to</code> is not specified or empty</p> </li> <li>System fetches all superuser emails from Django User model</li> <li> <p>Only superusers with valid, non-empty email addresses are included</p> </li> <li> <p>No Recipients Error - If both conditions fail</p> </li> <li>A <code>ValueError</code> exception is raised</li> <li>The full email content is logged to error logs</li> <li>Task monitoring fails with clear error message</li> </ol>"},{"location":"administrator/manual/django-monitor-task/#recipient-resolution-examples","title":"Recipient Resolution Examples","text":"<p>Example 1: Custom Recipients </p><pre><code>\"notify_to\": [\"admin@example.com\", \"devops@example.com\"]\n</code></pre> \u2192 Emails sent to: <code>admin@example.com</code>, <code>devops@example.com</code> <p>Example 2: Empty notify_to (Superuser Fallback) </p><pre><code>\"notify_to\": []  # or not specified\n</code></pre> \u2192 Emails sent to: All superusers with email addresses <p>Example 3: No Recipients Available </p><pre><code>\"notify_to\": []  # Empty\n# AND no superusers exist\n</code></pre> \u2192 Error: <code>ValueError: notify_to is empty but no superuser found for task 'task_name'</code>"},{"location":"administrator/manual/django-monitor-task/#setting-up-superusers","title":"Setting Up Superusers","text":"<p>If you want to use the superuser fallback:</p> <pre><code>python manage.py createsuperuser\n</code></pre> <p>Ensure the superuser has a valid email address during creation.</p>"},{"location":"administrator/manual/django-monitor-task/#best-practices","title":"Best Practices","text":"<ol> <li>Use explicit <code>notify_to</code> for critical tasks</li> <li>Ensures specific people are notified</li> <li> <p>Not dependent on superuser configuration</p> </li> <li> <p>Use superuser fallback for general monitoring</p> </li> <li>Automatic recipient management</li> <li> <p>New superusers automatically receive notifications</p> </li> <li> <p>Always have at least one notification method</p> </li> <li>Either specify <code>notify_to</code> OR ensure superusers exist</li> <li>System will raise error if neither is available</li> </ol>"},{"location":"administrator/manual/django-monitor-task/#email-notifications","title":"Email Notifications","text":""},{"location":"administrator/manual/django-monitor-task/#email-content","title":"Email Content","text":"<p>Notification emails include:</p> <ul> <li>Task name - Identifies which task has an issue</li> <li>Current status - Actual status found (or \"No execution found\")</li> <li>Expected status(es) - What statuses were acceptable</li> <li>Lookback window - Time window checked (e.g., \"Last 1 hour(s)\")</li> <li>Execution times - When task last started/finished (if available)</li> <li>Check timestamp - When the monitoring check was performed</li> <li>Dependent tasks warning - Tasks that may be affected (if specified)</li> </ul>"},{"location":"administrator/manual/django-monitor-task/#email-scenarios","title":"Email Scenarios","text":""},{"location":"administrator/manual/django-monitor-task/#scenario-1-status-doesnt-match-expected","title":"Scenario 1: Status Doesn't Match Expected","text":"<p>When a task is found but has wrong status:</p> <p></p> <p>Subject: <code>[ALERT] {task_name} Status Check Failed</code></p> <p>Key Information: - Shows actual status vs expected status - Includes execution timestamps - Provides lookback window context</p>"},{"location":"administrator/manual/django-monitor-task/#scenario-2-task-hasnt-executed","title":"Scenario 2: Task Hasn't Executed","text":"<p>When no task execution found within lookback window:</p> <p></p> <p>Subject: <code>[ALERT] {task_name} Has Not Executed</code></p> <p>Key Information: - Clear \"No execution found\" status - Shows the time window checked - Note about task not executing within expected timeframe</p>"},{"location":"administrator/manual/django-monitor-task/#scenario-3-dependent-tasks-warning","title":"Scenario 3: Dependent Tasks Warning","text":"<p>When a task with dependencies fails:</p> <p></p> <p>Subject: <code>[ALERT] {task_name} Status Check Failed</code></p> <p>Key Information: - All standard task information - Warning box highlighting dependent tasks - List of tasks that may be delayed or fail</p>"},{"location":"administrator/manual/django-monitor-task/#email-subjects","title":"Email Subjects","text":"<p>The system uses different subject lines based on the scenario:</p> <ul> <li>Status mismatch: <code>[ALERT] {task_name} Status Check Failed</code></li> <li>No execution: <code>[ALERT] {task_name} Has Not Executed</code></li> </ul>"},{"location":"administrator/manual/django-monitor-task/#email-template-customization","title":"Email Template Customization","text":"<p>The HTML email template is located at:</p> <pre><code>django_project/frontend/templates/emails/task_status_alert.html\n</code></pre>"},{"location":"administrator/manual/django-monitor-task/#customizing-the-template","title":"Customizing the Template","text":"<ol> <li>Edit the template file at the path above</li> <li>Maintain the context variables used in the template</li> <li>Test thoroughly with your email client</li> </ol>"},{"location":"administrator/manual/django-monitor-task/#available-template-variables","title":"Available Template Variables","text":"Variable Type Description <code>task_name</code> str Name of the monitored task <code>current_status</code> str Current status or \"No execution found\" <code>expected_statuses</code> str Comma-separated expected statuses (title case) <code>lookback_hours</code> float Lookback window in hours <code>started_at</code> datetime Last task start time (or None) <code>finished_at</code> datetime Last task finish time (or None) <code>check_time</code> datetime When the check was performed <code>has_dependent_tasks</code> bool Whether dependent tasks are specified <code>dependent_tasks</code> list List of dependent task names"},{"location":"administrator/manual/django-monitor-task/#example-template-customization","title":"Example Template Customization","text":"<p>Add your company logo:</p> <pre><code>&lt;div class=\"header\"&gt;\n    &lt;img src=\"https://yourcompany.com/logo.png\" alt=\"Logo\" style=\"height: 40px;\"&gt;\n    &lt;h1&gt;\u26a0\ufe0f Task Status Alert&lt;/h1&gt;\n&lt;/div&gt;\n</code></pre> <p>Customize colors:</p> <pre><code>.header {\n    background-color: #your-brand-color;\n    color: white;\n}\n</code></pre> <p>Add custom footer:</p> <pre><code>&lt;div class=\"footer\"&gt;\n    &lt;strong&gt;Action Required:&lt;/strong&gt; Please investigate immediately.\n    &lt;br&gt;&lt;br&gt;\n    Contact: support@yourcompany.com | Internal Docs: https://wiki.yourcompany.com/monitoring\n&lt;/div&gt;\n</code></pre>"},{"location":"administrator/manual/django-monitor-task/#testing-your-template","title":"Testing Your Template","text":"<pre><code># Start Django shell\npython manage.py shell\n\n# Test the template rendering\nfrom gap.tasks.monitoring import _send_notification\nfrom django.utils import timezone\n\n# This will attempt to send a test email\n# Ensure you have email configured or use console backend for testing\n</code></pre>"},{"location":"administrator/manual/django-monitor-task/#troubleshooting","title":"Troubleshooting","text":""},{"location":"administrator/manual/django-monitor-task/#issue-task-not-appearing-in-django-admin-dropdown","title":"Issue: Task Not Appearing in Django Admin Dropdown","text":"<p>Solution: Manually type <code>monitor_task_status</code> in the \"Task (registered)\" field.</p> <p>The task may not appear in the dropdown initially but will work when typed manually.</p>"},{"location":"administrator/manual/django-monitor-task/#issue-notifications-not-being-sent","title":"Issue: Notifications Not Being Sent","text":"<p>Checklist: 1. \u2713 Is the periodic task enabled in Django Admin? 2. \u2713 Is Celery Beat running? 3. \u2713 Are there superusers with email addresses (if <code>notify_to</code> not specified)? 4. \u2713 Check Celery logs for errors 5. \u2713 Verify email configuration in Django settings</p> <p>Debug Test: </p><pre><code>python manage.py shell\n\nfrom gap.tasks.monitoring import monitor_task_status\n\nconfig = {\n    \"test_task\": {\n        \"expected_statuses\": [\"Completed\"],\n        \"lookback_hours\": 24\n    }\n}\n\nresult = monitor_task_status(config)\nprint(result)\n</code></pre>"},{"location":"administrator/manual/django-monitor-task/#issue-valueerror-notify_to-is-empty-but-no-superuser-found","title":"Issue: ValueError - \"notify_to is empty but no superuser found\"","text":"<p>Cause: No recipients configured and no superusers exist.</p> <p>Solutions:</p> <ol> <li> <p>Add email addresses to config: </p><pre><code>{\n  \"task_name\": {\n    \"expected_statuses\": [\"Completed\"],\n    \"notify_to\": [\"admin@example.com\"]\n  }\n}\n</code></pre> </li> <li> <p>Create a superuser: </p><pre><code>python manage.py createsuperuser\n</code></pre> </li> </ol> <p>What happens: The full email content is logged to error logs before the exception is raised.</p>"},{"location":"administrator/manual/django-monitor-task/#issue-task-found-but-status-not-matching","title":"Issue: Task Found But Status Not Matching","text":"<p>Check: - Verify task name exactly matches <code>BackgroundTask.task_name</code> - Check if lookback window is appropriate - Review task execution logs</p> <p>Query BackgroundTask directly: </p><pre><code>from core.models.background_task import BackgroundTask\nfrom django.utils import timezone\nfrom datetime import timedelta\n\nlookback = timezone.now() - timedelta(hours=1)\ntasks = BackgroundTask.objects.filter(\n    task_name='your_task_name',\n    started_at__gte=lookback\n).order_by('-started_at')\n\nfor task in tasks:\n    print(f\"{task.started_at}: {task.status}\")\n</code></pre>"},{"location":"administrator/manual/django-monitor-task/#issue-no-task-found-in-lookback-window","title":"Issue: No Task Found in Lookback Window","text":"<p>Possible causes: - Task hasn't run recently - Lookback window too short - Task name mismatch</p> <p>Solutions: - Increase <code>lookback_hours</code> - Verify exact task name (case-sensitive) - Check BackgroundTask table for task execution history</p>"},{"location":"administrator/manual/django-monitor-task/#advanced-context-model-validation","title":"Advanced: Context Model Validation","text":"<p>For tasks that use context models (like <code>IngestorSession</code> or <code>CollectorSession</code>), you can validate the context type to monitor specific task variants.</p>"},{"location":"administrator/manual/django-monitor-task/#use-case","title":"Use Case","text":"<p>You want to monitor specifically \"Hourly Tomorrow.io\" ingestion, not all ingestor sessions.</p>"},{"location":"administrator/manual/django-monitor-task/#configuration","title":"Configuration","text":"<pre><code>{\n  \"ingestor_session\": {\n    \"context_model\": \"gap.models.IngestorSession\",\n    \"context_type\": \"Hourly Tomorrow.io\",\n    \"expected_statuses\": [\"Completed\"],\n    \"lookback_hours\": 2\n  }\n}\n</code></pre>"},{"location":"administrator/manual/django-monitor-task/#how-it-works_1","title":"How It Works","text":"<ol> <li>Finds most recent <code>ingestor_session</code> BackgroundTask</li> <li>Gets the associated IngestorSession instance using <code>context_id</code></li> <li>Validates that <code>ingestor_type == \"Hourly Tomorrow.io\"</code></li> <li>Only checks status if context validation passes</li> </ol>"},{"location":"administrator/manual/django-monitor-task/#supported-context-models","title":"Supported Context Models","text":"Model Validation Field <code>gap.models.IngestorSession</code> <code>ingestor_type</code> <code>gap.models.CollectorSession</code> <code>ingestor_type</code>"},{"location":"administrator/manual/django-monitor-task/#best-practices_1","title":"Best Practices","text":""},{"location":"administrator/manual/django-monitor-task/#1-start-simple","title":"1. Start Simple","text":"<p>Begin with basic monitoring for critical tasks:</p> <pre><code>{\n  \"critical_task\": {\n    \"expected_statuses\": [\"Completed\"],\n    \"notify_to\": [\"admin@example.com\"],\n    \"lookback_hours\": 2\n  }\n}\n</code></pre>"},{"location":"administrator/manual/django-monitor-task/#2-use-descriptive-periodic-task-names","title":"2. Use Descriptive Periodic Task Names","text":"<p>Good: <code>Monitor Hourly Data Collection Tasks</code> Bad: <code>Task Monitor 1</code></p>"},{"location":"administrator/manual/django-monitor-task/#3-set-appropriate-schedules","title":"3. Set Appropriate Schedules","text":"<ul> <li>Check 5-10 minutes after expected task completion</li> <li>For hourly tasks expected at :00, check at :05 or :10</li> <li>Don't check too frequently (wastes resources)</li> </ul>"},{"location":"administrator/manual/django-monitor-task/#4-document-dependencies","title":"4. Document Dependencies","text":"<p>Always list <code>dependent_tasks</code> to help responders understand impact:</p> <pre><code>{\n  \"data_collection\": {\n    \"dependent_tasks\": [\"data_processing\", \"report_generation\"]\n  }\n}\n</code></pre>"},{"location":"administrator/manual/django-monitor-task/#5-test-before-production","title":"5. Test Before Production","text":"<ol> <li>Create test periodic task with short interval</li> <li>Verify emails are received</li> <li>Check email formatting</li> <li>Adjust configuration as needed</li> </ol>"},{"location":"administrator/manual/django-monitor-task/#6-monitor-the-monitor","title":"6. Monitor the Monitor","text":"<ul> <li>Set up alerting if monitoring tasks themselves fail</li> <li>Review Celery Beat logs regularly</li> <li>Ensure monitoring tasks are running</li> </ul>"},{"location":"administrator/manual/django-monitor-task/#7-use-appropriate-lookback-windows","title":"7. Use Appropriate Lookback Windows","text":"<p>Refer to the Lookback Hours Explanation section for guidelines.</p>"},{"location":"administrator/manual/django-monitor-task/#complete-example-workflow","title":"Complete Example Workflow","text":""},{"location":"administrator/manual/django-monitor-task/#scenario-monitor-daily-report-generation","title":"Scenario: Monitor Daily Report Generation","text":"<p>Task Details: - Task runs daily at 8:00 AM UTC - Usually completes within 30 minutes - Creates reports used by management team - Dependent on data collection tasks</p> <p>Step 1: Create Periodic Task</p> <p>Name: <code>Monitor Daily Report Generation</code></p> <p>Step 2: Configure Arguments</p> <pre><code>[\n  {\n    \"generate_daily_report\": {\n      \"expected_statuses\": [\"Completed\"],\n      \"notify_to\": [\"reports-team@example.com\", \"management@example.com\"],\n      \"dependent_tasks\": [\"send_report_emails\", \"update_dashboard\"],\n      \"lookback_hours\": 2\n    }\n  }\n]\n</code></pre> <p>Step 3: Set Schedule</p> <p>Crontab: <code>35 8 * * *</code> (8:35 AM UTC - 35 minutes after expected completion)</p> <p>Step 4: Enable and Save</p> <p>\u2713 Check \"Enabled\" box and save</p> <p>Step 5: Monitor Results</p> <ul> <li>Check Celery logs for monitoring execution</li> <li>Verify emails are received when tests fail</li> <li>Adjust <code>lookback_hours</code> if needed</li> </ul>"},{"location":"administrator/manual/django-table/","title":"TomorrowNow - Global Access Platform (GAP)","text":""},{"location":"administrator/manual/django-table/#django-tables","title":"Django Tables","text":""},{"location":"administrator/manual/django-table/#user-table","title":"User Table","text":"<p>The user table within the Django Admin interface allows administrators to manage user-related tasks efficiently.</p> <ol> <li> <p>Add User: Clicking on the <code>ADD USER</code> button allows administrators to add a new user. Click on add user to see detailed documentation on adding a new user.</p> </li> <li> <p>Filter: Available filters to filter the records of the user table.</p> <ul> <li> <p></p> </li> <li> <p>Clear All Filters: Clicking on the <code>clear all filters</code> allows administrators to clear all the filters.</p> </li> <li> <p>Filter Field: The names of the filter field and attributes for filtering the records.</p> </li> </ul> </li> <li> <p>Search Functionality: The administrators can search the records using the search functionality.</p> </li> <li> <p>User Table: The user table with records.</p> </li> <li> <p>Edit User: Clicking on the object allows the administrators to change or edit a particular record. Click here to view detailed documentation on editing a user.</p> </li> </ol>"},{"location":"administrator/manual/django-table/#r-model-table","title":"R Model Table","text":"<p>The R Model table within the GAP Admin interface allows researchers to manage and track different versions of the R code used to produce plant/no plant signals.</p> <p></p> <ol> <li> <p>Add R Model: Clicking on the <code>ADD R MODEL</code> button allows researchers to add a new version of the R code. Click here to see detailed documentation on adding a new R model.</p> </li> <li> <p>R Model Table: The R Model table with records, displaying information such as the version number, description, and date added.</p> </li> <li> <p>Action Dropdown: The Action dropdown of the R Model table and allows researchers to perform various actions on the records. To access the Action Dropdown, click on the dropdown.</p> <p></p> <p>Performing Actions: To perform an action on a record, follow these steps:</p> <ul> <li> <p>Select Records: Check the box available in front of the records to perform the action on.</p> </li> <li> <p>Choose Action: Select the desired action from the dropdown menu.</p> </li> <li> <p>Go Button: Click on the Go button to execute the chosen action.</p> </li> </ul> <p>The available actions include:</p> <ul> <li> <p>Delete selected r model: Permanently remove the selected record(s) from the R Model table.</p> </li> <li> <p>Restart plumber process: Restarts the plumber process.</p> </li> </ul> </li> <li> <p>Edit R Model: Clicking on the object allows researchers to change or edit a particular version of the R code. Click here to view detailed documentation on editing an R model.</p> </li> </ol>"},{"location":"administrator/manual/django-table/#auth-model-table","title":"Auth Model Table","text":"<ol> <li> <p>Add Auth Token: Clicking on the 1\ufe0f\u20e3 <code>ADD Auth Token</code> button allows researchers to add a new token to auth model. Click here to see detailed documentation on adding a new Auth Token.</p> </li> <li> <p>Auth Model Table: The Auth Model table with records, displaying information such as the Digest, User, Created date and Expiry date.</p> </li> <li> <p>Action Dropdown: The Action dropdown of the Auth model table allows user to perform various actions on the records. To access the Action Dropdown, click on the dropdown.</p> <p></p> <p>Perform Action: To perform an action on a record, follow these steps :</p> <ul> <li> <p>Select Records: Check the box available in front of the records to perform the action on.</p> </li> <li> <p>Choose Action: Select the desired action from the dropdown menu.</p> </li> <li> <p>Go Button: Click on the Go button to execute the chosen action.</p> </li> </ul> <p>The available actions include:</p> <ul> <li>Delete selected auth tokens: Permanently remove the selected record(s) from the Auth Model table.</li> </ul> </li> <li> <p>Edit Auth Model: Clicking on the object allows user to modify or edit a specific Auth Model table record. Click here to view detailed documentation on editing an Auth Model.</p> </li> </ol>"},{"location":"developer/","title":"Documentation","text":""},{"location":"developer/#for-developers","title":"For Developers","text":"<p>This is the homepage for all developer related documentation.</p> <ul> <li>The API Guide, which aims to get you familiar with the APIs.</li> </ul>"},{"location":"developer/architecture/","title":"TomorrowNow - Global Access Platform (GAP)","text":""},{"location":"developer/architecture/#architecture","title":"Architecture","text":""},{"location":"developer/architecture/#architecture-diagram","title":"Architecture diagram","text":""},{"location":"developer/architecture/#data-flow-diagram","title":"Data flow diagram","text":""},{"location":"developer/architecture/#data-ingestors","title":"Data ingestors","text":""},{"location":"developer/architecture/#cbam-historical-reanalysis","title":"CBAM historical reanalysis","text":"<p>Zarr structure for CBAM dataset: </p><pre><code>&lt;xarray.Dataset&gt; Size: 160GB\nDimensions:                        (date: 4384, lat: 1205, lon: 841)\nCoordinates:\n  * date                           (date) datetime64[ns] 35kB 2012-01-01 ... ...\n  * lat                            (lat) float64 10kB -27.0 -26.97 ... 16.03\n  * lon                            (lon) float64 7kB 21.78 21.82 ... 51.99 52.03\nData variables:\n    average_solar_irradiance       (date, lat, lon) float32 18GB dask.array&lt;chunksize=(90, 300, 300), meta=np.ndarray&gt;\n    max_day_temperature            (date, lat, lon) float32 18GB dask.array&lt;chunksize=(90, 300, 300), meta=np.ndarray&gt;\n    max_night_temperature          (date, lat, lon) float32 18GB dask.array&lt;chunksize=(90, 300, 300), meta=np.ndarray&gt;\n    max_total_temperature          (date, lat, lon) float32 18GB dask.array&lt;chunksize=(90, 300, 300), meta=np.ndarray&gt;\n    min_day_temperature            (date, lat, lon) float32 18GB dask.array&lt;chunksize=(90, 300, 300), meta=np.ndarray&gt;\n    min_night_temperature          (date, lat, lon) float32 18GB dask.array&lt;chunksize=(90, 300, 300), meta=np.ndarray&gt;\n    min_total_temperature          (date, lat, lon) float32 18GB dask.array&lt;chunksize=(90, 300, 300), meta=np.ndarray&gt;\n    total_evapotranspiration_flux  (date, lat, lon) float32 18GB dask.array&lt;chunksize=(90, 300, 300), meta=np.ndarray&gt;\n    total_solar_irradiance         (date, lat, lon) float32 18GB dask.array&lt;chunksize=(90, 300, 300), meta=np.ndarray&gt;\n</code></pre>"},{"location":"developer/architecture/#salient-seasonal-forecast","title":"Salient seasonal forecast","text":"<p>Zarr structure for Salient dataset: </p><pre><code>&lt;xarray.Dataset&gt; Size: 11GB\nDimensions:           (ensemble: 50, forecast_day_idx: 91, forecast_date: 2,\n                       lat: 174, lon: 123)\nCoordinates:\n    analog            (ensemble, forecast_day_idx) datetime64[ns] 36kB dask.array&lt;chunksize=(50, 20), meta=np.ndarray&gt;\n  * ensemble          (ensemble) int64 400B 0 1 2 3 4 5 6 ... 44 45 46 47 48 49\n  * forecast_date     (forecast_date) datetime64[ns] 16B 2024-09-04 2024-09-09\n  * forecast_day_idx  (forecast_day_idx) int64 728B 0 1 2 3 4 ... 86 87 88 89 90\n  * lat               (lat) float64 1kB -27.12 -26.88 -26.62 ... 15.88 16.12\n  * lon               (lon) float64 984B 21.63 21.88 22.13 ... 51.63 51.88 52.13\nData variables: (12/21)\n    precip            (forecast_date, ensemble, forecast_day_idx, lat, lon) float32 779MB dask.array&lt;chunksize=(2, 50, 20, 20, 20), meta=np.ndarray&gt;\n    precip_anom       (forecast_date, ensemble, forecast_day_idx, lat, lon) float32 779MB dask.array&lt;chunksize=(2, 50, 20, 20, 20), meta=np.ndarray&gt;\n    precip_clim       (forecast_date, forecast_day_idx, lat, lon) float32 16MB dask.array&lt;chunksize=(2, 20, 20, 20), meta=np.ndarray&gt;\n    rh                (forecast_date, ensemble, forecast_day_idx, lat, lon) float32 779MB dask.array&lt;chunksize=(2, 50, 20, 20, 20), meta=np.ndarray&gt;\n    rh_anom           (forecast_date, ensemble, forecast_day_idx, lat, lon) float32 779MB dask.array&lt;chunksize=(2, 50, 20, 20, 20), meta=np.ndarray&gt;\n    rh_clim           (forecast_date, forecast_day_idx, lat, lon) float32 16MB dask.array&lt;chunksize=(2, 20, 20, 20), meta=np.ndarray&gt;\n    ...                ...\n    tsi               (forecast_date, ensemble, forecast_day_idx, lat, lon) float32 779MB dask.array&lt;chunksize=(2, 50, 20, 20, 20), meta=np.ndarray&gt;\n    tsi_anom          (forecast_date, ensemble, forecast_day_idx, lat, lon) float32 779MB dask.array&lt;chunksize=(2, 50, 20, 20, 20), meta=np.ndarray&gt;\n    tsi_clim          (forecast_date, forecast_day_idx, lat, lon) float32 16MB dask.array&lt;chunksize=(2, 20, 20, 20), meta=np.ndarray&gt;\n    wspd              (forecast_date, ensemble, forecast_day_idx, lat, lon) float32 779MB dask.array&lt;chunksize=(2, 50, 20, 20, 20), meta=np.ndarray&gt;\n    wspd_anom         (forecast_date, ensemble, forecast_day_idx, lat, lon) float32 779MB dask.array&lt;chunksize=(2, 50, 20, 20, 20), meta=np.ndarray&gt;\n    wspd_clim         (forecast_date, forecast_day_idx, lat, lon) float32 16MB dask.array&lt;chunksize=(2, 20, 20, 20), meta=np.ndarray&gt;\n</code></pre>"},{"location":"developer/architecture/#tomorrowio-short-term-forecast","title":"Tomorrow.io short-term forecast","text":"<p>Zarr structure for Tomorrow.io dataset: </p><pre><code>&lt;xarray.Dataset&gt; Size: - GB\nDimensions:           (forecast_date: 2, forecast_day_idx: 15, lat: 174, lon: 123)\nCoordinates:\n  * forecast_date     (forecast_date) datetime64[ns] 16B 2024-09-04 2024-09-05\n  * forecast_day_idx  (forecast_day_idx) int64 728B 0 1 2 3 4 ... 11 12 13 14\n  * lat               (lat) float64 1kB -27.12 -26.88 -26.62 ... 15.88 16.12\n  * lon               (lon) float64 984B 21.63 21.88 22.13 ... 51.63 51.88 52.13\nData variables: (12/21)\n    total_rainfall                   (forecast_date, forecast_day_idx, lat, lon) float32 -MB dask.array&lt;chunksize=(15, 15, 150, 110), meta=np.ndarray&gt;\n    total_evapotranspiration_flux    (forecast_date, forecast_day_idx, lat, lon) float32 -MB dask.array&lt;chunksize=(15, 15, 150, 110), meta=np.ndarray&gt;\n    max_total_temperature            (forecast_date, forecast_day_idx, lat, lon) float32 -MB dask.array&lt;chunksize=(15, 15, 150, 110), meta=np.ndarray&gt;\n    min_total_temperature            (forecast_date, forecast_day_idx, lat, lon) float32 -MB dask.array&lt;chunksize=(15, 15, 150, 110), meta=np.ndarray&gt;\n    precipitation_probability        (forecast_date, forecast_day_idx, lat, lon) float32 -MB dask.array&lt;chunksize=(15, 15, 150, 110), meta=np.ndarray&gt;\n    humidity_maximum                 (forecast_date, forecast_day_idx, lat, lon) float32 -MB dask.array&lt;chunksize=(15, 15, 150, 110), meta=np.ndarray&gt;\n    humidity_minimum                 (forecast_date, forecast_day_idx, lat, lon) float32 -MB dask.array&lt;chunksize=(15, 15, 150, 110), meta=np.ndarray&gt;\n    wind_speed_avg                   (forecast_date, forecast_day_idx, lat, lon) float32 -MB dask.array&lt;chunksize=(15, 15, 150, 110), meta=np.ndarray&gt;\n</code></pre>"},{"location":"developer/architecture/#tahmo-ground-observations","title":"Tahmo ground observations","text":""},{"location":"developer/architecture/#arable-ground-observations","title":"Arable ground observations","text":""},{"location":"developer/architecture/#gap-modules","title":"GAP Modules","text":""},{"location":"developer/architecture/#spw-data-flow-diagram","title":"SPW data flow diagram","text":""},{"location":"developer/data-model/","title":"Documentation","text":""},{"location":"developer/data-model/#data-model-diagram","title":"Data model diagram","text":""},{"location":"developer/data-model/#gap","title":"GAP","text":""},{"location":"developer/data-model/#spw","title":"SPW","text":""},{"location":"developer/hyrax-config/","title":"Documentation","text":""},{"location":"developer/hyrax-config/#hyrax-configuration","title":"Hyrax Configuration","text":"<p>Hyrax is a data server developed by OPeNDAP as a reference server for the Data Access Protocol, versions 2 and 4. This documentation shows how to integrate Hyrax into GAP Platform to read NetCDF files that are hosted in S3 Object Storage.</p>"},{"location":"developer/hyrax-config/#pre-requisites","title":"Pre-requisites","text":"<ul> <li>NetCDF Files hosted in a S3 bucket</li> <li>AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY</li> <li>AWS_ENDPOINT_URL (optional) if using a different storage server (e.g. minio)</li> <li>Local volume for mounting file cache</li> <li>Hyrax image: opendap/hyrax:1.17.0-122</li> <li>PyDAP package for reading URL from OpenDAP: pydap==3.4.1</li> <li>numpy==1.26.4 is needed for pydap that is not compatible with latest numpy version</li> </ul>"},{"location":"developer/hyrax-config/#important-notes","title":"Important Notes","text":"<p>When NetCDF files are hosted in S3, we can leverage DMR++ files to access the NetCDF file using subsetting. This is useful to avoid caching the full NetCDF file before reading it. To learn more about DMR++, click here.</p> <p>However, the downside is that we need to generate DMR++ files first and put them in the Hyrax data directory. Use below command to generate the DMR++ file.</p> <pre><code>get_dmrpp -b $(pwd) -o output.dmrpp -u http://minio:9000/tomorrownow/cbam/2019-11-06.nc.h5 s3://tomorrownow/cbam/2019-11-06.nc.h5\n</code></pre> <ul> <li>http://minio:9000/tomorrownow/cbam/2019-11-06.nc.h5 is a URL to access the file. This URL will be included in the output.dmrpp file</li> <li>s3://tomorrownow/cbam/2019-11-06.nc.h5 is the location that get_dmrpp binary will try to find the NetCDF file</li> <li>get_dmrpp binary will use aws cli and it's recommended to upgrade to aws cli v2 to support endpoint-url in the AWS config file.</li> <li>Configure endpoint-url in ~/.aws/config if endpoint-url is not a default AWS URL (e.g. minio).</li> </ul>"},{"location":"developer/hyrax-config/#cbam-datasets","title":"CBAM Datasets","text":"<p>We need to rename the NetCDF Files from CBAM to make the Hyrax and get_dmrpp binary able to read the files. The Hyrax is using a regex to determine the Backend Module for reading and the CBAM files seems to be a HDF5 files.</p> <pre><code>mv 2019-11-01.nc 2019-11-01.nc.h5\n</code></pre>"},{"location":"developer/hyrax-config/#salient-datasets","title":"Salient Datasets","text":"<p>We encountered error when generating DMR++ file for Salient Data Sample file, so the only option is to copy the whole NetCDF file into Hyrax Data Directory. When checking the type of NetCDF using command <code>ncdump -k downscale_2024-03-13_rwanda.nc</code>, the type is <code>64-bit offset</code> which may not compatible with get_dmrpp binary. However, we do not need to rename the file with h5 like we do for CBAM datasets.</p>"},{"location":"developer/hyrax-config/#custom-siteconf","title":"Custom site.conf","text":"<p>Below is the custom configuration for Hyrax:</p> <pre><code># allow minio to allowed host Hyrax for dev\nAllowedHosts+=^http:\\/\\/minio\\:9000\\/.*$\nGateway.Whitelist+=http://minio:9000\n# use parallel transfers\nDMRPP.UseParallelTransfers = yes\n# fix error on finding effective url during caching\nHttp.cache.effective.urls=false\n# credentials manager\nCredentialsManager.config=/etc/bes/credentials.conf\n\nDAP.GlobalMetadataStore.path = /usr/share/mds\nDAP.Use.Dmrpp = yes\n</code></pre>"},{"location":"developer/hyrax-config/#s3-credentials","title":"S3 Credentials","text":"<p>To allow Hyrax accessing S3, the credentials.conf must be used. We created a custom <code>entrypoint.sh</code> script that will write during the startup of the container.</p> <pre><code>#!/bin/bash\n\nfile=\"/etc/bes/credentials.conf\"\n\nif [ -f \"$file\" ] ; then\n    rm \"$file\"\nfi\n\ntouch \"$file\"\necho \"tomorrownow = url:${AWS_ENDPOINT_URL}${S3_AWS_BUCKET_NAME}/\" &gt;&gt; \"$file\"\necho \"tomorrownow += id:${AWS_ACCESS_KEY_ID}\" &gt;&gt; \"$file\"\necho \"tomorrownow += key:${AWS_SECRET_ACCESS_KEY}\" &gt;&gt; \"$file\"\necho \"tomorrownow += region:us-east-1\" &gt;&gt; \"$file\"\necho \"tomorrownow += bucket:${AWS_ENDPOINT_URL}\" &gt;&gt; \"$file\"\n\nchmod 600 \"$file\"\nchown bes:bes \"$file\"\n\n# run original entrypoint\n./entrypoint.sh\n</code></pre>"},{"location":"developer/hyrax-config/#hyrax-service-in-docker-compose-files","title":"Hyrax Service in docker compose files","text":"<p>docker-compose.yml </p><pre><code>  hyrax:\n    image: opendap/hyrax:1.17.0-122\n    ports:\n      - \"8181:8080\"\n    environment:\n      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-minio_tomorrownow}\n      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-minio_tomorrownow}\n      - AWS_ENDPOINT_URL=${AWS_ENDPOINT_URL}\n      - S3_AWS_BUCKET_NAME=${S3_AWS_BUCKET_NAME:-tomorrownow}\n    volumes:\n      - hyrax-data:/usr/share/hyrax\n    restart: always\n</code></pre> <p>docker-compose.override.yml </p><pre><code>  hyrax:\n    entrypoint: [ \"/custom_entrypoint.sh\" ]\n    volumes:\n      - ./volumes/hyrax_data:/usr/share/hyrax\n      - ./hyrax/site.conf:/etc/bes/site.conf:ro\n      - ./hyrax/entrypoint.sh:/custom_entrypoint.sh\n    links:\n      - django\n      - worker\n</code></pre> <p><code>/volumes/hyrax_data</code> is the volume for storing cache of dmrpp files or Salient data files. </p>"},{"location":"developer/hyrax-config/#accessing-hyrax-ui","title":"Accessing Hyrax UI","text":"<p>Hyrax has a UI that can be accessed in http://localhost:8181/opendap/.</p> <p></p> <p>We can query using html UI and export the data into different format like csv.</p> <p></p> <p>Note: we can use slicing syntax to access the data: [start:step:end].</p>"},{"location":"developer/hyrax-config/#accessing-using-python-script","title":"Accessing using Python Script","text":""},{"location":"developer/hyrax-config/#cbam-dataset","title":"CBAM Dataset","text":"<pre><code>from pydap.client import open_url, open_dods_url\n\nCBAM_METADATA = {\n    'lon': {\n        'min': 26.9665,\n        'inc': 0.036006329,\n        'size': 475\n    },\n    'lat': {\n        'min': -12.5969,\n        'inc': 0.03574368,\n        'size': 539\n    }\n}\n\ndef find_idx(value, base_min, inc):\n    return round((value - base_min) / inc)\n\n# Function to slice along multiple specified axes\ndef slice_along_axes(array, indices):\n    slices = [slice(None)] * array.ndim  # Create a list of slices\n\n    # Set the slices for the specified axes\n    for axis, index in indices.items():\n        slices[axis] = index\n\n    return array[tuple(slices)]\n\n\nsearch_lat = -3.25\nsearch_lon = 30.4\nidx_lat = find_idx(search_lat, CBAM_METADATA['lat']['min'], CBAM_METADATA['lat']['inc'])\nidx_lon = find_idx(search_lon, CBAM_METADATA['lon']['min'], CBAM_METADATA['lon']['inc'])\ndataset = open_url('http://hyrax:8080/opendap/cbam/2019-11-09.nc.h5.dmrpp')\nmtt = dataset['max_total_temperature']\nresult = slice_along_axes(mtt['max_total_temperature'], {1: idx_lat, 2: idx_lon})\nprint(result)\n</code></pre>"},{"location":"developer/hyrax-config/#salient-dataset","title":"Salient Dataset","text":"<pre><code>from pydap.client import open_url, open_dods_url\n\nSALIENT_METADATA = {\n    'lon': {\n        'min': 28.875,\n        'inc': 0.25,\n        'size': 9\n    },\n    'lat': {\n        'min': -2.875,\n        'inc': 0.25,\n        'size': 8\n    }\n}\n\ndef find_idx(value, base_min, inc):\n    return round((value - base_min) / inc)\n\n# Function to slice along multiple specified axes\ndef slice_along_axes(array, indices):\n    slices = [slice(None)] * array.ndim  # Create a list of slices\n\n    # Set the slices for the specified axes\n    for axis, index in indices.items():\n        slices[axis] = index\n\n    return array[tuple(slices)]\n\n\nsearch_lat = -2.215\nsearch_lon = 29.125\nidx_lat = find_idx(search_lat, SALIENT_METADATA['lat']['min'], CBAM_METADATA['lat']['inc'])\nidx_lon = find_idx(search_lon, SALIENT_METADATA['lon']['min'], CBAM_METADATA['lon']['inc'])\ndataset = open_url('http://hyrax:8080/opendap/salient/downscale_2024-03-13_rwanda.nc')\ntemp_clim = dataset.temp_clim\nresult = slice_along_axes(temp_clim['temp_clim'], {1: idx_lat, 2: idx_lon})\nprint(result)\n</code></pre>"},{"location":"developer/api/guide/","title":"Documentation","text":""},{"location":"developer/api/guide/#api-user-guide","title":"API user guide","text":"<ul> <li>API Keys: this section shows a tutorial to create and delete API keys.</li> <li>Measurement API: this section explains the measurement API guide for both GET and POST method.</li> <li>Overview - Introduction to OSIRIS II Global Access Platform</li> <li>Data Products - Available weather and climate data products</li> <li>Attributes Reference - Complete list of attributes for each product</li> <li>Getting Started - Authentication and basic API usage</li> <li>Advanced Usage - Code examples, location upload, and error codes</li> <li>Access API Using R: this section shows a tutorial to access the API using R.</li> <li>Access API in Jupyter Notebook: this section shows a tutorial to access the API in Jupyter Notebook.</li> </ul>"},{"location":"developer/api/guide/access-api-using-jupyter/","title":"Documentation","text":""},{"location":"developer/api/guide/access-api-using-jupyter/#accessing-gap-api-using-jupyter-notebook","title":"Accessing GAP API using Jupyter Notebook","text":"<p>This tutorial demonstrates how to download a NetCDF file from GAP API, save it locally, and reading it using Python libraries in a Jupyter Notebook. We'll use requests for the download and xarray for processing.</p>"},{"location":"developer/api/guide/access-api-using-jupyter/#requirements","title":"Requirements","text":"<ol> <li> <p>Python Libraries:</p> <ul> <li>requests for downloading files from an API.</li> <li>xarray for reading and working with NetCDF files.</li> <li>netCDF4 as a backend for xarray to handle NetCDF data.</li> <li>matplotlib (Optional) for plotting the data.</li> </ul> <p>Install these libraries using the following commands:</p> <pre><code>pip install requests xarray netCDF4 matplotlib\n</code></pre> </li> <li> <p>Jupyter Notebook: If Jupyter is not already installed, you can install it with:</p> <pre><code>pip install notebook\n</code></pre> </li> </ol>"},{"location":"developer/api/guide/access-api-using-jupyter/#running-the-code","title":"Running the Code","text":"<ol> <li> <p>Download the sample code</p> <ul> <li>You can download the full code from here.</li> <li>There is also a python sample code that you can download from here. You can use this sample code to run without jupyter notebook by running: <code>python sample.py</code>.</li> </ul> </li> <li> <p>Open Jupyter Notebook: Launch the notebook by running:</p> <pre><code>jupyter notebook\n</code></pre> </li> <li> <p>Open the downloaded sample code</p> <ul> <li>Select the file <code>sample.ipynb</code></li> <li>Click Open</li> </ul> </li> <li> <p>Set the username and password</p> <pre><code># Set your username and password\nusername = \"\"\npassword = \"\"\n</code></pre> </li> <li> <p>Define your query parameters</p> <ul> <li>The sample code shows query to CBAM Historical Analysis dataset and save the output to netcdf file.</li> <li>The query is using bounding box of Kenya, you can also define another area bounding box or use the lat/lon for single query. Another option is to upload a shapefile for custom bounding box/polygon, then use location_name in the query_params.</li> </ul> <pre><code># product type and attribute list can be viewed in\n# https://kartoza.github.io/tomorrownow_gap/developer/api/guide/measurement/#gap-input-data-table\nproduct = 'cbam_historical_analysis'\n# Define the attributes to fetch\nattribs = [\n    \"max_temperature\",\n    \"min_temperature\"\n]\n# start and end dates in format YYYY-MM-DD\nstart_date = '2020-01-01'\nend_date = '2020-01-03'\n# available output type: json, csv, netcdf\n# Note that json output is only for single location query\noutput_type = 'netcdf'\n# area bounding box (long min, lat min, long max, lat max)\nbbox = '33.9, -4.67, 41.89, 5.5'\n# for single point query, we can use lat and lon parameters\n# lat = '',\n# lon = ''\n# for custom polygon/bounding box, you can upload a shapefile and provides the location_name\n# location_name = ''\n</code></pre> </li> <li> <p>Set the output file path</p> <pre><code># Set the output file path\nlocal_filename = \"data.nc\"\n</code></pre> </li> <li> <p>Run the code by clicking the  button or <code>Run &gt; Run All Cells</code>.</p> </li> </ol>"},{"location":"developer/api/guide/access-api-using-jupyter/#expected-output","title":"Expected Output","text":"<p>If the download is successful:</p> <ol> <li> <p>The file will be saved locally with the specified filename (e.g., data.nc).</p> </li> <li> <p>The ncdf4 library will print metadata and a list of variables in the NetCDF file, e.g.:</p> <pre><code>Reading NetCDF file with xarray...\n&lt;xarray.Dataset&gt; Size: 2MB\nDimensions:          (date: 3, lat: 285, lon: 222)\nCoordinates:\n  * date             (date) datetime64[ns] 24B 2020-01-01 2020-01-02 2020-01-03\n  * lat              (lat) float64 2kB -4.662 -4.626 -4.59 ... 5.418 5.454 5.489\n  * lon              (lon) float64 2kB 33.92 33.95 33.99 ... 41.8 41.84 41.87\nData variables:\n    max_temperature  (date, lat, lon) float32 759kB ...\n    min_temperature  (date, lat, lon) float32 759kB ...\n</code></pre> </li> <li> <p>If matplotlib is installed, then the chart of max_temperature will be plotted.</p> </li> </ol> <p>If the download fails:</p> <p>The script will display an error message with the HTTP status code, e.g.:</p> <pre><code>Failed to download file. HTTP Status Code: 404\n</code></pre>"},{"location":"developer/api/guide/access-api-using-r/","title":"Documentation","text":""},{"location":"developer/api/guide/access-api-using-r/#accessing-gap-api-using-r","title":"Accessing GAP API using R","text":"<p>This tutorial demonstrates how to download a NetCDF file from GAP API, save it locally, and read it using R. We'll use httr for downloading the file and the ncdf4 library for reading NetCDF data.</p>"},{"location":"developer/api/guide/access-api-using-r/#requirements","title":"Requirements","text":"<ol> <li> <p>R Environment:</p> <ul> <li>Install R and RStudio (optional but recommended for running scripts interactively).</li> </ul> </li> <li> <p>R Libraries:</p> <ul> <li>curl: Dependency for httr</li> <li>httr: For making HTTP requests to download the file.</li> <li>ncdf4: For reading NetCDF files.</li> <li>fields: (Optional), for plotting</li> </ul> <p>Install these packages using the following commands in R:</p> <pre><code>install.packages(\"curl\")\ninstall.packages(\"httr\")\ninstall.packages(\"ncdf4\")\ninstall.packages(\"fields\")\n</code></pre> <p>If <code>ncdf4</code> package installation failed, then you can need to install <code>libnetcdf-dev</code> library on your operating system. Below is the example to install the package on Ubuntu. Once installed, run <code>install.packages(\"ncdf4\")</code> again on RStudio. </p> <pre><code>sudo apt-get update -y\nsudo apt-get install -y libnetcdf-dev\n</code></pre> <p>For windows, you can follow the installation guide of ncdf4 from this link.</p> </li> </ol>"},{"location":"developer/api/guide/access-api-using-r/#running-the-code","title":"Running the Code","text":"<ol> <li> <p>Download the sample code</p> <ul> <li>You can download the full code from here.</li> <li>Once you have downloaded the sample code, then you can open the file from RStudio (File -&gt; Open File).</li> <li>Other example fetch by points is to show an example fetching the data by list of point from CSV file.</li> </ul> </li> <li> <p>Set the username and password</p> <pre><code># Set your username and password\nusername &lt;- '&lt;YOUR_USERNAME&gt;'\npassword &lt;- '&lt;YOUR_PASSWORD&gt;'\n</code></pre> </li> <li> <p>Define your query parameters</p> <ul> <li>The sample code shows query to CBAM Historical Analysis dataset and save the output to netcdf file.</li> <li>The query is using bounding box of Kenya, you can also define another area bounding box or use the lat/lon for single query. Another option is to upload a shapefile for custom bounding box/polygon, then use location_name in the query_params.</li> </ul> <pre><code># Define the request parameters\nquery_params &lt;- list(\n    # product type and attribute list can be viewed in\n    # https://kartoza.github.io/tomorrownow_gap/developer/api/guide/measurement/#gap-input-data-table\n    product = 'cbam_historical_analysis',\n    # comma separated string (without space)\n    attributes = 'max_temperature,min_temperature',\n    # start and end dates in format YYYY-MM-DD\n    start_date = '2020-01-01',\n    end_date = '2020-01-03',\n    # available output type: json, csv, netcdf\n    # Note that json output is only for single location query\n    output_type = 'netcdf',\n    # area bounding box (long min, lat min, long max, lat max)\n    bbox = '33.9, -4.67, 41.89, 5.5'\n    # for single point query, we can use lat and lon parameters\n    # lat = '',\n    # lon = ''\n    # for custom polygon/bounding box, you can upload a shapefile and provides the location_name\n    # location_name = ''\n)\n</code></pre> </li> <li> <p>Set the output file path</p> <pre><code># Set the output file path\noutput_file &lt;- \"data.nc\"\n</code></pre> </li> <li> <p>Run the code using: <code>Code -&gt; Run Region -&gt; Run All</code>.</p> </li> </ol>"},{"location":"developer/api/guide/access-api-using-r/#expected-output","title":"Expected Output","text":"<p>If the download is successful:</p> <ol> <li> <p>The file will be saved locally with the specified filename (e.g., data.nc).</p> </li> <li> <p>The ncdf4 library will print metadata and a list of variables in the NetCDF file, e.g.:</p> <pre><code>File data.nc (NC_FORMAT_NETCDF4):\n\n    2 variables (excluding dimension variables):\n        float max_temperature[lon,lat,date]   (Contiguous storage)  \n            _FillValue: NaN\n            Description: Maximum temperature (0000:2300)\n            Units: Deg C\n        float min_temperature[lon,lat,date]   (Contiguous storage)  \n            _FillValue: NaN\n            Description: Minimum temperature (0000:2300)\n            Units: Deg C\n\n    3 dimensions:\n        date  Size:3 \n            units: days since 2012-01-01\n            calendar: proleptic_gregorian\n        lat  Size:285 \n            _FillValue: NaN\n            dtype: float32\n            long_name: Latitude\n            units: degrees_north\n        lon  Size:222 \n            _FillValue: NaN\n            dtype: float32\n            long_name: Longitude\n            units: degrees_east\n</code></pre> </li> </ol> <p>If the download fails:</p> <p>The script will display an error message with the HTTP status code, e.g.:</p> <pre><code>Failed to download file. HTTP Status Code: 404\n</code></pre>"},{"location":"developer/api/guide/access-api-using-r/#exploring-the-dataset","title":"Exploring the Dataset","text":"<p>After successfully loading the file:</p> <ol> <li> <p>List All Variables:</p> <pre><code>print(variables)\n</code></pre> </li> <li> <p>Extract Data from a Variable:</p> <pre><code>nc &lt;- nc_open(local_filename)\nmax_temperature &lt;- ncvar_get(nc, \"max_temperature\")\nnc_close(nc)\n</code></pre> </li> <li> <p>Visualize Data</p> <ul> <li> <p>Install the fields package for plotting:</p> <pre><code>install.packages(\"fields\")\nlibrary(fields)\nimage.plot(temperature[,,1])  # Plot the first time step\n</code></pre> </li> </ul> </li> </ol>"},{"location":"developer/api/guide/api-keys/","title":"Documentation","text":""},{"location":"developer/api/guide/api-keys/#managing-api-keys-on-the-global-access-platform","title":"Managing API Keys on the Global Access Platform","text":"<p>This guide explains how to generate, copy, and delete API keys from the Global Access Platform.</p>"},{"location":"developer/api/guide/api-keys/#1-open-the-platform","title":"1. Open the Platform","text":"<p>Go to the Global Access Platform. Click the profile icon in the top-right corner.</p> <p></p>"},{"location":"developer/api/guide/api-keys/#2-open-api-key-settings","title":"2. Open API Key Settings","text":"<p>From the dropdown menu, select API Keys.</p> <p></p>"},{"location":"developer/api/guide/api-keys/#3-view-api-keys-page","title":"3. View API Keys Page","text":"<p>You will see the My API Keys page. Click on Generate new to create a new API key.</p> <p></p>"},{"location":"developer/api/guide/api-keys/#4-create-a-new-api-key","title":"4. Create a New API Key","text":"<p>Fill in the required details:</p> <ol> <li>Token Name </li> <li>Token Description </li> <li>Expiration Date </li> <li>Click Create</li> </ol> <p></p>"},{"location":"developer/api/guide/api-keys/#5-copy-the-api-key","title":"5. Copy the API Key","text":"<p>After creation, the API key will be shown only once. Click Copy to save it securely.</p> <p></p>"},{"location":"developer/api/guide/api-keys/#6-api-key-list","title":"6. API Key List","text":"<p>Your API key will now appear in the list of keys with its name, description, created date, and expiry date.</p> <p></p>"},{"location":"developer/api/guide/api-keys/#7-delete-an-api-key","title":"7. Delete an API Key","text":"<p>To remove an API key, click the trash icon next to the key.</p> <p></p>"},{"location":"developer/api/guide/api-keys/#8-confirm-deletion","title":"8. Confirm Deletion","text":"<p>Confirm the action by clicking Delete.</p> <p></p>"},{"location":"developer/api/guide/api-keys/#9-api-key-removed","title":"9. API Key Removed","text":"<p>The list will be empty once the API key has been deleted.</p> <p></p>"},{"location":"developer/api/guide/api-keys/#notes","title":"Notes","text":"<ul> <li>API keys are shown once \u2014 always copy and store them securely.  </li> <li>Expired or deleted keys cannot be recovered.  </li> <li>Use API keys for secure programmatic access to the Global Access Platform.</li> </ul>"},{"location":"developer/api/guide/measurements/advanced-usage/","title":"Advanced Usage","text":""},{"location":"developer/api/guide/measurements/advanced-usage/#advanced-usage","title":"Advanced Usage","text":"<p>Example of codes to access the API</p>"},{"location":"developer/api/guide/measurements/advanced-usage/#python","title":"Python","text":"<pre><code>import requests\nfrom requests.auth import HTTPBasicAuth\n\nurl = \"https://gap.tomorrownow.org/api/v1/measurement/?lat=-1.404244&amp;lon=35.008688&amp;attributes=max_temperature,min_temperature&amp;start_date=2019-11-01&amp;end_date=2019-11-02&amp;product=cbam_historical_analysis&amp;output_type=json\"\n\npayload={}\n\n# --- Option 1: Using username and password ---\nheaders = {}\nbasic = HTTPBasicAuth('YOUR_USERNAME', 'YOUR_PASSWORD')\nresponse = requests.get(url, auth=basic, data=payload)\nprint(response.json())\n\n# --- Option 2: Using API Token ---\ntoken = \"YOUR_API_TOKEN\"\nheaders = {'Authorization': f'Token {token}'}\nresponse = requests.get(url, headers=headers, data=payload)\nprint(response.json())\n</code></pre>"},{"location":"developer/api/guide/measurements/advanced-usage/#curl","title":"CURL","text":"<pre><code># --- Option 1: Using username and password ---\ncurl --location 'https://gap.tomorrownow.org/api/v1/measurement/?lat=-1.404244&amp;lon=35.008688&amp;attributes=max_temperature%2Cmin_temperature&amp;start_date=2019-11-01&amp;end_date=2019-11-02&amp;product=cbam_historical_analysis&amp;output_type=json' \\\n-u 'YOUR_USERNAME:YOUR_PASSWORD'\n\n# --- Option 2: Using API Token ---\ncurl --location 'https://gap.tomorrownow.org/api/v1/measurement/?lat=-1.404244&amp;lon=35.008688&amp;attributes=max_temperature%2Cmin_temperature&amp;start_date=2019-11-01&amp;end_date=2019-11-02&amp;product=cbam_historical_analysis&amp;output_type=json' \\\n--header 'Authorization: Token YOUR_API_TOKEN'\n</code></pre>"},{"location":"developer/api/guide/measurements/advanced-usage/#javascript-jquery","title":"JavaScript-JQuery","text":"<pre><code>var url = \"https://gap.tomorrownow.org/api/v1/measurement/?lat=-1.404244&amp;lon=35.008688&amp;attributes=max_temperature,min_temperature&amp;start_date=2019-11-01&amp;end_date=2019-11-02&amp;product=cbam_historical_analysis&amp;output_type=json\";\n\n// --- Option 1: Using username and password (Basic Auth) ---\nvar basicAuth = \"Basic \" + btoa(\"YOUR_USERNAME:YOUR_PASSWORD\");\n\n$.ajax({\n  url: url,\n  method: \"GET\",\n  timeout: 0,\n  headers: {\n    \"Authorization\": basicAuth\n  },\n}).done(function (response) {\n  console.log(response);\n});\n\n// --- Option 2: Using API Token ---\n$.ajax({\n  url: url,\n  method: \"GET\",\n  timeout: 0,\n  headers: {\n    \"Authorization\": \"Token YOUR_API_TOKEN\"\n  },\n}).done(function (response) {\n  console.log(response);\n});\n</code></pre>"},{"location":"developer/api/guide/measurements/advanced-usage/#upload-location-api","title":"Upload Location API","text":"<p>Using the Location API, you can upload the geometry to query the data by polygon or list of point. You can upload the geometry in one of format: geojson/shapefile/gpkg. The file must be in WGS84 or CRS 4326. The uploaded location will have expiry date time (2 months). Once the server removes your geometry after the expiry time, you need to reupload your geometry.</p> <p>Note: when using shapefile, the .shp, .dbf, .shx files must be in the zip root directory.</p> <p>Click on the 1\ufe0f\u20e3 Upload Location POST API to view the usage option. Click on the 2\ufe0f\u20e3 <code>Try it out</code> button, to enable the fields to enter the attributes.</p> <p></p> <p>Fill the location_name and select your file to upload in the 1\ufe0f\u20e3 available fields. After filling the details click on the 2\ufe0f\u20e3 <code>Execute</code> button, to run the API.</p> <p></p> <p>Example of response:</p> <p></p> <p>You can see the expiry date time for your geometry in the <code>expired_on</code> field.</p>"},{"location":"developer/api/guide/measurements/advanced-usage/#api-postman-collection","title":"API Postman Collection","text":"<p>You can download the postman collection below and import the API collection using your postman. Once imported, you need to set the variable <code>gap_api_username</code> and <code>gap_api_password</code> using your credentials.</p> <p>Download</p>"},{"location":"developer/api/guide/measurements/advanced-usage/#error-codes","title":"Error codes","text":"Response code Message Reason 400 Attribute with ensemble cannot be mixed with non-ensemble When requesting for product type salient_seasonal_forecast and output is csv, the attribute that is in ensemble (50-values) cannot be requested with the attribute that does not have ensemble. Please use netcdf output format instead! 400 Incorrect output type Use either json, csv, netcdf or ascii 400 No matching attribute found! The attribute list cannot be found in the product type. 400 Output format json is only available for single point query! JSON output is only available for GET method with singe point query. Please use csv/netcdf output format! 400 Unknown geometry type! Use geometry with type Polygon/Multipolygon/MultiPoint to make a request using POST method 404 No weather data is found for given queries 429 Too many requests You have hit the rate limit"},{"location":"developer/api/guide/measurements/data-products/","title":"GAP Data Products","text":""},{"location":"developer/api/guide/measurements/data-products/#gap-input-data-table","title":"GAP Input Data Table","text":""},{"location":"developer/api/guide/measurements/data-products/#historical-data","title":"Historical Data","text":"Product Provider Resolution Source Version API product_type Automated Weather Stations (Arable) 2024-2025 Arable weather stations 300+ stations across East Africa Arable (API) 2024-2025 arable_ground_observation Automated Weather Stations (TAHMO) (QC/QA) 2018 - 2025 v1 TAHMO weather stations 300+ stations across East Africa TAHMO Gap Filled Data (csv) 2018-2025 v1 tahmo_ground_observation CBAM Daily Reanalysis (Bias-Corrected) 2012-2023 v1 Tomorrow.io 4km x 4km Tomorrow.io CBAM 1F enhanced bias-corrected reanalysis 2012-2023 v1 cbam_historical_analysis_bias_adjust CBAM Daily Reanalysis (Raw) 2012-2024 v2 Tomorrow.io 4km x 4km Tomorrow.io CBAM 1F enhanced bias-corrected reanalysis 2012-2024 v2 cbam_historical_analysis Disdrometer (Laser Rain Gauge) disdrometers Tahmo (API) disdrometer_ground_observation Google Gencast Google 27830m Google WeatherNext Gen Forecasts google_gencast Google Graphcast Google 27830m Google WeatherNext Graph Forecasts google_graphcast Radiosonde Observations (Windborne) WindBorne Systems 100 weather balloons Windborne Systems windborne_radiosonde_observation TAMSAT Precipitation Long-term Normals (20-year) TAMSAT tamsat_ltn"},{"location":"developer/api/guide/measurements/data-products/#weather-forecasts","title":"Weather Forecasts","text":"Product Provider Resolution Source Version API product_type CBAM Weather Forecast Daily 10-day Tomorrow.io 4km x 4km Tomorrow.io CBAM satellite enhanced short-term weather forecasts cbam_shortterm_forecast CBAM Weather Forecast Hourly 4-day Tomorrow.io 4km x 4km Tomorrow.io CBAM satellite enhanced short-term weather forecasts cbam_shortterm_hourly_forecast Google Gencast Google 27830m Google WeatherNext Gen Forecasts google_gencast Google Graphcast Google 27830m Google WeatherNext Graph Forecasts google_graphcast Google Nowcast Google 5km x 5km google_nowcast Salient Predictions Weather Forecast - GEMv2 (3-month) Salient 28km x 28km Salient (API) v9 salient_gemv2_forecast Salient Predictions Weather Forecast - Sub-seasonal to Seasonal (8-month) Salient 28km x 28km Salient (API) v9 salient_seasonal_forecast <p>Note: The Today value from the CBAM short term weather forecast is stored and can be accessed for historical records dating back to 12 October 2024.</p> <p>Note on Google Gencast and Graphcast lead times: When Google runs the Gencast model between 00:00 to 12:00, it is marked as 12:00. On GAP, the timestamp is adjusted to 00:00, so the lead time is decreased by 12 hours. The same applies to Graphcast, but with a 6-hour adjustment.</p>"},{"location":"developer/api/guide/measurements/getting-started/","title":"Getting Started","text":""},{"location":"developer/api/guide/measurements/getting-started/#getting-started-with-the-api","title":"Getting Started with the API","text":"<p>In order to use the API, the user must be authenticated and must have authorisation to access the data.</p> <p>Let's see how to use the API and what sequence of API calls can lead us to get data for analysis.</p> <p>Once you open the above link the Swagger will open. Click on the 1\ufe0f\u20e3 <code>Authorize</code> button, to open the authorisation form.</p> <p></p> <p>To authorize, please enter your <code>Username</code> and <code>Password</code> Once you have entered your credentials, click the <code>Authorize</code> button to complete the authorisation process.</p> <p></p> <p>Click on the close button or cross button to close the authorisation form.</p> <p></p> <p>Examples of Usage of the OSIRIS II API</p> <p>Please note that the data in the examples provided below DO NOT reflect the actual data in TomorrowNow.</p>"},{"location":"developer/api/guide/measurements/getting-started/#accessing-the-osiris-ii-api","title":"Accessing the OSIRIS II API","text":"<p>To use the API click on the Weather &amp; Climate Data 1\ufe0f\u20e3.</p> <p></p> <p>Weather &amp; Climate Data API:</p> <p>Click on the GET API it will show the parameters to enter to get the data. Click on the 1\ufe0f\u20e3 <code>Try it out</code> button, to fill the detailed in the 2\ufe0f\u20e3 available request parameters. After filling the details click on the 3\ufe0f\u20e3 <code>Execute</code> button, to run the API.</p> <p> </p> <p>Example of response:</p> <p></p> <p>Available format types</p>"},{"location":"developer/api/guide/measurements/getting-started/#json","title":"JSON","text":"<p>This type is only available for querying by single point. </p>"},{"location":"developer/api/guide/measurements/getting-started/#csv","title":"CSV","text":"<p>The user can download the file to check the response </p>"},{"location":"developer/api/guide/measurements/getting-started/#netcdf","title":"NETCDF","text":"<p>The user can download the file to check the response </p> <p>To read/write the netcdf file user can refer to below link https://docs.xarray.dev/en/stable/user-guide/io.html#netcdf</p>"},{"location":"developer/api/guide/measurements/ingestor-schedule/","title":"Ingestor Schedule","text":""},{"location":"developer/api/guide/measurements/ingestor-schedule/#gap-ingestor-schedule","title":"GAP Ingestor Schedule","text":"<p>Below is the ingestor schedule of datasets in GAP.</p> Dataset Frequency Model Run (UTC) Model Available (UTC) GAP Start Time (UTC) GAP End Time (UTC) Available Time (UTC) Retention Policy CBAM Daily Short-Term Forecast 00Z Once per day 00:00:00 \u2013 00:10:00 02:13:00 02:23:00 Stored in the latest and historical Zarr CBAM Daily Short-Term Forecast 06Z Twice per day 06:00:00 \u2013 08:30:00 09:20:00 09:40:00 \u2013 CBAM Hourly Short-Term Forecast Once per day \u2013 \u2013 00:30:00 06:03:00 06:43:00 Stored in the latest Zarr only (no historical archive) Google GenCast Once per day 00:00:00 08:05:00 09:05:00 09:43 10:00 Stored in the latest and historical Zarr Google GraphCast Once per day 18:00:00 00:45:00 02:00:00 02:30:00 02:35:00 Stored in the latest and historical Zarr Google Nowcast Four times per day (every 6 hours at :15 UTC) \u2013 \u2013 00:15:0006:15:0012:15:0018:15:00 00:45:0006:45:0012:45:0018:45:00 02:25:0007:00:0013:00:0019:00:00 00:00 and 12:00 models stored in the historical Zarr Salient Once per week (every Monday) \u2013 \u2013 04:00:00 04:52:00 05:58:00 Stored in the latest and historical Zarr Salient GEMV2 Once per week (every Monday) \u2013 \u2013 10:00:00 10:05:00 10:55:00 Stored in the latest and historical Zarr"},{"location":"developer/api/guide/measurements/overview/","title":"Documentation","text":""},{"location":"developer/api/guide/measurements/overview/#osiris-ii-global-access-platform","title":"OSIRIS II Global Access Platform","text":"<p>Project Overview</p> <p>TomorrowNow.org is partnering with the Bill and Melinda Gates Foundation (BMGF) to develop and assess new weather technologies to support the seed breeding ecosystem in East Africa. The \"Next-Gen\" project focuses on adopting new or next-generation technologies to improve data access and quality.</p> <p>Goals</p> <p>The project aims to address two key challenges limiting the uptake of weather data in Africa:</p> <ol> <li> <p>Data Access: Provide curated datasets from top weather data providers, streamlined APIs, and a global access strategy to ensure long-term, low-cost access to weather data.</p> </li> <li> <p>Data Quality: Localise forecast models using a network of ground observation stations, apply bias adjustment techniques, and produce analysis-ready datasets using best-practice quality control methods.</p> </li> </ol> <p>Objectives</p> <ul> <li> <p>Improve data quality by measuring and benchmarking data quality and cost across top models for historical climate reanalysis, short-term weather forecasting, and S2S weather forecasting.</p> </li> <li> <p>Enhance data access through a global access strategy and partnerships with data providers.</p> </li> </ul> <p>Impact</p> <p>By addressing data access and quality challenges, the project aims to accelerate the adoption of weather intelligence across the smallholder farming ecosystem in East Africa.</p> <p>TomorrowNow provides access to the data through a RESTful API, available at https://gap.tomorrownow.org/api/v1/docs/</p>"},{"location":"developer/api/guide/measurements/attributes-reference/arable-stations/","title":"Automated Weather Stations (Arable) 2024-2025","text":""},{"location":"developer/api/guide/measurements/attributes-reference/arable-stations/#automated-weather-stations-arable-2024-2025","title":"Automated Weather Stations (Arable) 2024-2025","text":"Name Description Unit API attribute name Max Day Temperature \u00b0C max_day_temperature Mean Day Temperature \u00b0C mean_day_temperature Min Day Temperature \u00b0C min_day_temperature Precipitation mm/day precipitation Precipitation Total mm precipitation_total Relative Humidity Max % max_relative_humidity Relative Humidity Mean % mean_relative_humidity Relative Humidity Min % min_relative_humidity Sea Level Pressure kPa sea_level_pressure Total Evapotranspiration Flux mm total_evapotranspiration_flux Wind Heading degree wind_heading Wind Speed m/s wind_speed Wind Speed Max m/s wind_speed_max Wind Speed Min m/s wind_speed_min"},{"location":"developer/api/guide/measurements/attributes-reference/cbam-daily-10day/","title":"CBAM Weather Forecast Daily 10-day","text":""},{"location":"developer/api/guide/measurements/attributes-reference/cbam-daily-10day/#cbam-weather-forecast-daily-10-day","title":"CBAM Weather Forecast Daily 10-day","text":"Name Description Unit API attribute name Flood Index flood_index Humidity Maximum % humidity_maximum Humidity Minimum % humidity_minimum Max Temperature \u00b0C max_temperature Min Temperature \u00b0C min_temperature Precipitation Probability % precipitation_probability Solar radiation Wh/m2 solar_radiation Total Evapotranspiration Flux mm total_evapotranspiration_flux Total Rainfall mm total_rainfall Weather Code weather_code Wind Speed Average m/s wind_speed_avg"},{"location":"developer/api/guide/measurements/attributes-reference/cbam-hourly-4day/","title":"CBAM Weather Forecast Hourly 4-day","text":""},{"location":"developer/api/guide/measurements/attributes-reference/cbam-hourly-4day/#cbam-weather-forecast-hourly-4-day","title":"CBAM Weather Forecast Hourly 4-day","text":"Name Description Unit API attribute name Flood Index flood_index Humidity % humidity Precipitation Probability % precipitation_probability Solar radiation Wh/m2 solar_radiation Temperature \u00b0C temperature Total Evapotranspiration Flux mm total_evapotranspiration_flux Total Rainfall mm total_rainfall Weather Code weather_code Wind Direction degree wind_direction Wind Speed m/s wind_speed"},{"location":"developer/api/guide/measurements/attributes-reference/cbam-reanalysis-bias-corrected/","title":"CBAM Daily Reanalysis (Bias-Corrected) 2012-2023 v1","text":""},{"location":"developer/api/guide/measurements/attributes-reference/cbam-reanalysis-bias-corrected/#cbam-daily-reanalysis-bias-corrected-2012-2023-v1","title":"CBAM Daily Reanalysis (Bias-Corrected) 2012-2023 v1","text":"Name Description Unit API attribute name Max Total Temperature Maximum temperature (0000:2300) \u00b0C max_temperature Min Total Temperature Minimum temperature (0000:2300) \u00b0C min_temperature Total Rainfall Total rainfall (0000:2300) mm total_rainfall Total Solar Irradiance Total solar irradiance reaching the surface (0000:2300) MJ/sqm total_solar_irradiance"},{"location":"developer/api/guide/measurements/attributes-reference/cbam-reanalysis-hourly/","title":"CBAM Reanalysis Hourly 2020-2022","text":""},{"location":"developer/api/guide/measurements/attributes-reference/cbam-reanalysis-hourly/#cbam-reanalysis-hourly-2020-2022","title":"CBAM Reanalysis Hourly 2020-2022","text":"Name Description Unit API attribute name Accumulated freezing rain Total accumulated amount of freezing rain over a given period mm thickness_of_freezing_rain_amount Accumulated rainfall Total accumulated liquid rainfall over a given period mm thickness_of_rainfall_amount Accumulated snowfall Total accumulated snowfall over a given period mm thickness_of_snowfall_amount Air pressure as measured just above the surface Atmospheric pressure measured just above the Earth's surface hPa surface_air_pressure Altitude of lowest cloud base Height of the lowest cloud base above ground level m cloud_base Altitude of lowest cloud ceiling Height of the lowest cloud ceiling above ground level m cloud_ceiling Column integrated soil temperature Average soil temperature integrated over the full soil column \u00b0C soil_temperature_total_column Column integrated volumetric soil moisture content Average volumetric soil moisture integrated over the full soil column % soil_moisture_total_column Dewpoint temperature at surface Dew point temperature measured at the surface \u00b0C sfc_dewpoint Feels Like temperature Perceived air temperature accounting for wind, humidity, and radiation \u00b0C sfc_feels_like Fire weather risk index Index indicating potential fire danger based on weather conditions Fire Index fosberg_fire_index Precipitation Probability Probability of precipitation occurring % precipitation_probability Precipitation Rate (liquid water equivalent) Rate of liquid-equivalent precipitation mm/day precip_rate Precipitation type Encoded type of precipitation (e.g. rain, snow, freezing rain) code precip_type Relative Humidity Relative humidity % relative_humidity Sea Level Pressure Atmospheric pressure reduced to mean sea level kPa sea_level_pressure Shortwave Radiation Incoming shortwave solar radiation at the surface W/m2 shortwave_radiation Soil temperature in slab between 100cm and 200cm Soil temperature averaged between 100 cm and 200 cm depth \u00b0C soil_temperature_depth_below_surface_layer_200cm Soil temperature in slab between 10cm and 40cm Soil temperature averaged between 10 cm and 40 cm depth \u00b0C soil_temperature_depth_below_surface_layer_40cm Soil temperature in slab between 40cm and 100cm Soil temperature averaged between 40 cm and 100 cm depth \u00b0C soil_temperature_depth_below_surface_layer_100cm Soil temperature in slab between sfc and 10cm Soil temperature averaged between the surface and 10 cm depth \u00b0C soil_temperature_depth_below_surface_layer_10cm Surface Air Temperature Air temperature measured at the surface \u00b0C surface_air_temperature The diffuse component of the total solar irradiance reaching the surface Diffuse shortwave solar radiation reaching the surface W/m2 diffuse_shortwave_radiation The direct component of the total solar irradiance reaching the surface Direct shortwave solar radiation reaching the surface W/m2 direct_shortwave_radiation Total cloud area Fraction of the sky covered by clouds % cloud_cover Total (cloud-cloud, cloud-ground) instantaneous lightning flashes per unit area Lightning flash frequency per unit area over a short time interval flashes/km2/5min frequency_of_lightning_flashes_per_unit_area Total Evapotranspiration Flux Total evapotranspiration flux over grass-covered surfaces mm total_evapotranspiration_flux Visibility near the surface Horizontal visibility measured near the surface m sfc_visibility Volumetric soil moisture content in slab between 100cm and 200cm Average volumetric soil moisture between 100 cm and 200 cm depth % soil_moisture_depth_below_surface_layer_200cm Volumetric soil moisture content in slab between 10cm and 40cm Average volumetric soil moisture between 10 cm and 40 cm depth % soil_moisture_depth_below_surface_layer_40cm Volumetric soil moisture content in slab between 40cm and 100cm Average volumetric soil moisture between 40 cm and 100 cm depth % soil_moisture_depth_below_surface_layer_100cm Volumetric soil moisture content in slab between sfc and 10cm Average volumetric soil moisture between the surface and 10 cm depth % soil_moisture_depth_below_surface_layer_10cm Wind Direction The direction from which the wind originates, measured clockwise from north degree wind_direction Wind Gusts Maximum instantaneous wind speed over a short period m/s wind_gusts Wind Speed Average horizontal wind speed m/s wind_speed"},{"location":"developer/api/guide/measurements/attributes-reference/cbam-reanalysis-raw/","title":"CBAM Daily Reanalysis (Raw) 2012-2024 v2","text":""},{"location":"developer/api/guide/measurements/attributes-reference/cbam-reanalysis-raw/#cbam-daily-reanalysis-raw-2012-2024-v2","title":"CBAM Daily Reanalysis (Raw) 2012-2024 v2","text":"Name Description Unit API attribute name Average Solar Irradiance Average hourly solar irradiance reaching the surface (0600:1800) MJ/sqm average_solar_irradiance Max Day Temperature Maximum day-time temperature (0600:1800) \u00b0C max_day_temperature Max Night Temperature Maximum night-time temperature (1900:0500) \u00b0C max_night_temperature Max Total Temperature Maximum temperature (0000:2300) \u00b0C max_temperature Min Day Temperature Minimum day-time temperature (0600:1800) \u00b0C min_day_temperature Min Night Temperature Minimum night-time temperature (1900:0500) \u00b0C min_night_temperature Min Total Temperature Minimum temperature (0000:2300) \u00b0C min_temperature Total Evapotranspiration Flux Total Evapotranspiration flux with respect to grass cover (0000:2300) mm total_evapotranspiration_flux Total Rainfall Total rainfall (0000:2300) mm total_rainfall Total Solar Irradiance Total solar irradiance reaching the surface (0000:2300) MJ/sqm total_solar_irradiance"},{"location":"developer/api/guide/measurements/attributes-reference/disdrometer/","title":"Disdrometer (Laser Rain Gauge)","text":""},{"location":"developer/api/guide/measurements/attributes-reference/disdrometer/#disdrometer-laser-rain-gauge","title":"Disdrometer (Laser Rain Gauge)","text":"Name Description Unit API attribute name Atmospheric Pressure kPa atmospheric_pressure Depth of Water mm depth_of_water Electrical Conductivity of Precipitation mS/cm electrical_conductivity_of_precipitation Electrical Conductivity of Water mS/cm electrical_conductivity_of_water Lightning Distance km lightning_distance Precipitation mm/day precipitation Precipitation Total mm precipitation_total Relative Humidity % relative_humidity Shortwave Radiation W/m2 shortwave_radiation Soil Moisture Content m3/m3 soil_moisture_content Soil Temperature \u00b0C soil_temperature Surface Air Temperature \u00b0C surface_air_temperature Wind Gusts m/s wind_gusts Wind Heading degree wind_heading Wind Speed m/s wind_speed"},{"location":"developer/api/guide/measurements/attributes-reference/google-gencast/","title":"Google Gencast 15-day Forecast","text":""},{"location":"developer/api/guide/measurements/attributes-reference/google-gencast/#google-gencast-15-day-forecast","title":"Google Gencast 15-day Forecast","text":"<p>Note on lead times: When Google runs the Gencast model between 00:00 to 12:00, it is marked as 12:00. On GAP, the timestamp is adjusted to 00:00, so the lead time is decreased by 12 hours.</p> Name Description Unit API attribute name 10 meter U wind component Zonal (west\u2013east) component of wind measured at 10 meters above ground m/s 10m_u_component_of_wind 10 meter V wind component Meridional (south\u2013north) component of wind measured at 10 meters above ground m/s 10m_v_component_of_wind 2 meter temperature Air temperature measured at 2 meters above ground level K 2m_temperature Total precipitation over a 12-hour period Total accumulated precipitation over a 12-hour period m total_precipitation_12hr"},{"location":"developer/api/guide/measurements/attributes-reference/google-graphcast/","title":"Google Graphcast 10-day Forecast","text":""},{"location":"developer/api/guide/measurements/attributes-reference/google-graphcast/#google-graphcast-10-day-forecast","title":"Google Graphcast 10-day Forecast","text":"<p>Note on lead times: When Google runs the Graphcast model between 00:00 to 06:00, it is marked as 06:00. On GAP, the timestamp is adjusted to 00:00, so the lead time is decreased by 6 hours.</p> Name Description Unit API attribute name 10 meter U wind component Zonal (west\u2013east) component of wind measured at 10 meters above ground m/s 10m_u_component_of_wind 10 meter V wind component Meridional (south\u2013north) component of wind measured at 10 meters above ground m/s 10m_v_component_of_wind Temperature Air temperature at the specified model level or surface \u00b0C temperature Total precipitation over a 6-hour period Total accumulated precipitation over a 6-hour period mm/day total_precipitation_6hr"},{"location":"developer/api/guide/measurements/attributes-reference/google-nowcast/","title":"Google Nowcast 12-hour Forecast","text":""},{"location":"developer/api/guide/measurements/attributes-reference/google-nowcast/#google-nowcast-12-hour-forecast","title":"Google Nowcast 12-hour Forecast","text":"Name Description Unit API attribute name Precipitation at a threshold of 0.2 mm Accumulated precipitation exceeding 0.2 mm within the given period mm/day precip_200_um Precipitation at a threshold of 0.4 mm Accumulated precipitation exceeding 0.4 mm within the given period mm/day precip_400_um Precipitation at a threshold of 1 mm Accumulated precipitation exceeding 1 mm within the given period mm/day precip_1000_um Precipitation at a threshold of 1.6 mm Accumulated precipitation exceeding 1.6 mm within the given period mm/day precip_1600_um Precipitation at a threshold of 2.4 mm Accumulated precipitation exceeding 2.4 mm within the given period mm/day precip_2400_um Precipitation at a threshold of 4.0 mm Accumulated precipitation exceeding 4.0 mm within the given period mm/day precip_4000_um Precipitation at a threshold of 5.0 mm Accumulated precipitation exceeding 5.0 mm within the given period mm/day precip_5000_um Precipitation at a threshold of 7.0 mm Accumulated precipitation exceeding 7.0 mm within the given period mm/day precip_7000_um Precipitation at a threshold of 10 mm Accumulated precipitation exceeding 10 mm within the given period mm/day precip_10000_um Precipitation at a threshold of 25 mm Accumulated precipitation exceeding 25 mm within the given period mm/day precip_25000_um Precipitation at a threshold of 30 mm Accumulated precipitation exceeding 30 mm within the given period mm/day precip_30000_um Precipitation type Encoded classification of precipitation type (e.g. rain, snow, freezing rain) code precip_type"},{"location":"developer/api/guide/measurements/attributes-reference/radiosonde/","title":"Radiosonde Observations (Windborne)","text":""},{"location":"developer/api/guide/measurements/attributes-reference/radiosonde/#radiosonde-observations-windborne","title":"Radiosonde Observations (Windborne)","text":"Name Description Unit API attribute name Atmospheric Pressure hPa atmospheric_pressure Relative Humidity % relative_humidity Specific Humidity mg/kg specific_humidity Temperature \u00b0C temperature"},{"location":"developer/api/guide/measurements/attributes-reference/salient-gemv2/","title":"Salient Predictions Weather Forecast GEMv2 (3-month)","text":""},{"location":"developer/api/guide/measurements/attributes-reference/salient-gemv2/#salient-predictions-weather-forecast-gemv2-3-month","title":"Salient Predictions Weather Forecast GEMv2 (3-month)","text":"Name Description Unit API attribute name Max Temperature Maximum air temperature over the period 0000\u20132300 \u00b0C max_temperature Min Temperature Minimum air temperature over the period 0000\u20132300 \u00b0C min_temperature Precipitation Total accumulated precipitation over the given period mm/day precipitation Relative Humidity Relative humidity % relative_humidity Solar radiation Total incoming solar radiation over the given period Wh/m2 solar_radiation Temperature Air temperature at the specified time or level \u00b0C temperature Wind Speed Average horizontal wind speed m/s wind_speed"},{"location":"developer/api/guide/measurements/attributes-reference/salient-seasonal-forecast/","title":"Salient Predictions Weather Forecast Sub-seasonal to Seasonal (8-month)","text":""},{"location":"developer/api/guide/measurements/attributes-reference/salient-seasonal-forecast/#salient-predictions-weather-forecast-sub-seasonal-to-seasonal-8-month","title":"Salient Predictions Weather Forecast Sub-seasonal to Seasonal (8-month)","text":"Name Description Unit API attribute name Downward Solar Radiation kWh m-2 day-1 solar_radiation Downward Solar Radiation Anomaly kWh m-2 day-1 solar_radiation_anom Downward Solar Radiation Climatology kWh m-2 day-1 solar_radiation_clim Maximum Temperature \u00b0C max_temperature Maximum Temperature Anomaly \u00b0C max_temperature_anom Maximum Temperature Climatology \u00b0C max_temperature_clim Minimum Temperature \u00b0C min_temperature Minimum Temperature Anomaly \u00b0C min_temperature_anom Minimum Temperature Climatology \u00b0C min_temperature_clim Precipitation mm day-1 precipitation Precipitation Anomaly mm day-1 precipitation_anom Precipitation Climatology mm day-1 precipitation_clim Relative Humidity % relative_humidty Relative Humidity Anomaly % relative_humidty_anom Relative Humidity Climatology % relative_humidty_clim Temperature \u00b0C temperature Temperature Anomaly \u00b0C temperature_anom Temperature Climatology \u00b0C temperature_clim Wind Speed m/s wind_speed Wind Speed Anomaly m/s wind_speed_anom Wind Speed Climatology m/s wind_speed_clim"},{"location":"developer/api/guide/measurements/attributes-reference/tahmo-stations/","title":"Automated Weather Stations (TAHMO) (QC/QA) 2018 - 2025 v1","text":""},{"location":"developer/api/guide/measurements/attributes-reference/tahmo-stations/#automated-weather-stations-tahmo-qcqa-2018-2025-v1","title":"Automated Weather Stations (TAHMO) (QC/QA) 2018 - 2025 v1","text":"Name Description Unit API attribute name Air Temperature Average \u00b0C average_air_temperature Air Temperature Max \u00b0C max_air_temperature Air Temperature Min \u00b0C min_air_temperature Precipitation mm/day precipitation Precipitation Total Chirps % precipitation_total_chirps Precipitation Total Chirps Qflag % precipitation_total_chirps_qflag Precipitation Total Era5 % precipitation_total_era5 Precipitation Total Qflag % precipitation_total_qflag Relative Humidity Max % max_relative_humidity Relative Humidity Min % min_relative_humidity Solar radiation Wh/m2 solar_radiation"},{"location":"developer/api/guide/measurements/attributes-reference/tamsat-ltn/","title":"TAMSAT Precipitation Long-term Normals (20-year)","text":""},{"location":"developer/api/guide/measurements/attributes-reference/tamsat-ltn/#tamsat-precipitation-long-term-normals-20-year","title":"TAMSAT Precipitation Long-term Normals (20-year)","text":"Name Description Unit API attribute name Precipitation Total mm precipitation_total"},{"location":"developer/django/architecture-overview/","title":"Django Application","text":"<p>Django React Base is built on a modern web stack template that leverages the power of Django, PostgreSQL, and Cloud Native GIS (vector tiles, COGS) for geospatial capabilities. The architecture is designed to be modular, scalable, and maintainable, allowing for easy integration of new features and data sources.</p>"},{"location":"developer/django/architecture-overview/#key-components","title":"Key Components","text":"<ul> <li>Django: The web framework that powers the application, providing a robust backend for handling requests, managing data, and serving the frontend.</li> <li>PostgreSQL: The relational database that stores all application data, including user information, geospatial data, and application settings.</li> <li>GeoDjango: An extension of Django that adds support for geographic data, enabling advanced geospatial queries and operations.</li> <li>Docker: Used for containerization, allowing the application to run consistently across different environments.</li> <li>Celery: A distributed task queue that handles background tasks, such as data processing and notifications, ensuring the application remains responsive.</li> <li>Redis: Serves as the message broker and cache layer that powers Celery and improves app performance.</li> <li>React: A JavaScript library for building interactive user interfaces and single-page applications (SPAs).</li> <li>Chakara: A React-based component library that provides accessible, responsive, and themeable UI components out of the box.</li> <li>MapLibre GL JS: An open-source mapping library for rendering interactive maps on the frontend.</li> </ul>"},{"location":"developer/django/architecture-overview/#architecture-diagram","title":"Architecture Diagram","text":"<p>To be populated</p>"},{"location":"developer/django/coding_standard/","title":"Django Application","text":""},{"location":"developer/django/coding_standard/#coding-standard","title":"Coding Standard","text":""},{"location":"developer/django/coding_standard/#general-approach","title":"General approach","text":"<ul> <li>Use github for revision control, issue tracking and management. And use the   the recommended workflow whenever possible.</li> <li>Adherence to regression/unit testing wherever possible (make test) with a   minimum code coverage of 80%.</li> <li>Develop in the spirit of XP/Agile, i.e. frequent releases, continuous   integration and iterative development. The main branch should always be   assumed to represent a working demo with all tests passing.</li> <li>If a method or function is longer than a single screen, it is probably a   candidate for refactoring into smaller methods / functions. Writing smaller   methods makes your code easier to read and to test.</li> <li>If you use a few lines of code in more than one place, refactor them into   their own function.</li> </ul>"},{"location":"developer/django/coding_standard/#platform-support","title":"Platform support","text":"<p>Currently the following platforms should be supported:</p> <ul> <li>OSX - latest release</li> <li>Linux - Ubuntu current LTS</li> <li>Windows</li> </ul>"},{"location":"developer/django/coding_standard/#compliance","title":"Compliance","text":"<ul> <li>In the case of Python, it follows PEP8, enforced automatically using Ruff on   check or on save file.</li> <li>The Ruff configuration applies standard PEP8 conventions, with a line length   of 100 characters and an indentation width of 4 spaces.</li> <li>Some docstring formatting checks (e.g. D200\u2013D415) and whitespace checks (e.g.   E203) have been disabled for better compatibility with modern formatting   tools.</li> </ul>"},{"location":"developer/django/coding_standard/#python-documentation-guide","title":"Python documentation guide","text":"<ul> <li>Docstrings should follow the Google Python Style Guide convention.</li> </ul> <pre><code>def sum(x: int, y: int) -&gt; int:\n    \"\"\"Returns the sum of two numbers.\n\n    Args:\n        x (int): First number.\n        y (int): Second number.\n\n    Returns:\n        int: The sum of the two numbers.\n    \"\"\"\n    return x + y\n</code></pre> <ul> <li>Each public function, class, and module should include a descriptive   docstring that explains its purpose, arguments, and return values.</li> <li>Missing docstring warnings are ignored for migration and settings files.</li> </ul>"},{"location":"developer/django/coding_standard/#code-quality-and-linting","title":"Code quality and linting","text":"<ul> <li>Code must pass a Ruff linting validation. You can test this using the   command:</li> </ul> <pre><code>ruff check .\n</code></pre> <ul> <li>In specific cases, you may temporarily disable a linting rule for a line or   block using the # noqa comment, for example:</li> </ul> <pre><code># noqa: F401\n</code></pre> <p>This should be used sparingly and only when necessary (e.g., intentional unused imports in init.py).</p>"},{"location":"developer/django/setup/","title":"Django React Base","text":""},{"location":"developer/django/setup/#setup-guides","title":"Setup Guides","text":"<p>We provide documentation for the most common operating systems in use at the time of writing. If you are using a different platform, you will need to adapt these instructions accordingly.</p> <p>\u270f\ufe0f Note: After following the platform specific guide applicable to your system, please follow the generic instructions.</p> Windows 11 Pro macOS 15 Ubuntu 24.04 LTS Generic Steps"},{"location":"developer/django/setup/setup-generic/","title":"Django React Base","text":""},{"location":"developer/django/setup/setup-generic/#generic-developer-setup","title":"Generic Developer Setup","text":"<p>This section of the documentation is designed to guide developers step by step through the process of setting up a development workstation.</p> <p>\u2b50\ufe0f Before running these generic steps, make sure you have completed the operating system specific steps available here.</p> <p>To get started, ensure that both Docker and Git are installed on your system. Begin with the Prerequisites section.</p> <p>Once the operating system specific steps are complete, continue with the following steps which apply to any OS:</p> <ul> <li>Cloning the repo</li> <li>Configuration</li> <li>Running Locally</li> <li>\ud83d\udea9 Removing</li> </ul>"},{"location":"developer/django/setup/setup-generic/cloning/","title":"Django React Base","text":""},{"location":"developer/django/setup/setup-generic/cloning/#cloning-the-code","title":"Cloning the Code","text":"<p>You need to check out over ssh - this implies that you have configured your GitHub account with an SSH key:</p> <pre><code>git clone git@github.com:kartoza/django-react-base.git\n</code></pre> <p>\ud83d\udcd2Which branch to use?: Note that we deploy our staging site from the <code>main</code> branch and our production environment from the latest release tag. If you are planning on contributing improvements to the project, please submit them against the <code>main</code> branch.</p> <p>\ud83e\udea7 Now that you have cloned the project, move on to the configuration.</p>"},{"location":"developer/django/setup/setup-generic/configuration/","title":"Django React Base","text":""},{"location":"developer/django/setup/setup-generic/configuration/#configuration","title":"Configuration","text":"<p>In this step, you'll update some files to get the project working \u2014 but don\u2019t worry, most of it is automated! All you need to do is:</p> <ol> <li>Navigate to the root of the project.</li> <li>Run the setup script:</li> </ol> <pre><code>./setup.sh\n</code></pre> <p>\ud83e\udea7 Now that the codebase is set up, you\u2019re ready to run the application. Continue to the run guide.</p> <p>You may also want to review how to set up other environments (see below) before running the project.</p>"},{"location":"developer/django/setup/setup-generic/configuration/#set-up-different-environment-optional","title":"Set up different environment (optional)","text":"<p>To edit the application settings (e.g. username of admin user, password of admin user, port of server etc.), use a text editor to edit deployment/.env. See the descriptions below for each of variable.</p> <pre><code>COMPOSE_PROJECT_NAME=django_react_base\nDJANGO_SETTINGS_MODULE=core.settings.dev\nDJANGO_TAG=0.0.1\nHTTP_PORT=80\n\nADMIN_USERNAME=admin\nADMIN_PASSWORD=admin\nADMIN_EMAIL=admin@example.com\n\nDATABASE_NAME=django\nDATABASE_USERNAME=docker\nDATABASE_PASSWORD=docker\nDATABASE_HOST=db\n\nREDIS_HOST=redis\nREDIS_PASSWORD=redis_password\n\nRABBITMQ_HOST=rabbitmq\nSENTRY_DSN=\n</code></pre> <p>\ud83e\udea7 Now that the codebase is set up, you\u2019re ready to run the application. Continue to the run guide.</p>"},{"location":"developer/django/setup/setup-generic/removing/","title":"Django React Base","text":""},{"location":"developer/django/setup/setup-generic/removing/#removing-your-development-environment","title":"Removing your development environment","text":"<p>If you want to completely remove the development environment you should do the following:</p> <ul> <li>\ud83d\udea9\ud83d\udea9\ud83d\udea9</li> <li>\ud83d\udea9\ud83d\udea9\ud83d\udea9</li> <li>WARNING: The commands listed here are destructive and may result in loss of work if you do not have backups!</li> <li>\ud83d\udea9\ud83d\udea9\ud83d\udea9</li> <li>\ud83d\udea9\ud83d\udea9\ud83d\udea9</li> </ul>"},{"location":"developer/django/setup/setup-generic/removing/#remove-the-code-tree","title":"Remove the code tree","text":"<p>To remove the code tree entirely:</p> <pre><code>rm -rf django-react-base/\n</code></pre>"},{"location":"developer/django/setup/setup-generic/removing/#removing-docker-containers","title":"Removing docker containers","text":"<p>To list all django_react_base docker containers:</p> <pre><code>docker ps -a | grep django_react_base\n</code></pre> <p>Example output:</p> <pre><code>ca145b57a7f7   kartoza/django_react_base:dev   \"/usr/sbin/sshd -D\"      45 seconds ago   Up 32 seconds             0.0.0.0:8001-&gt;22/tcp, [::]:8001-&gt;22/tcp, 0.0.0.0:8000-&gt;8080/tcp, [::]:8000-&gt;8080/tcp   django_react_base-dev-1\n2787af751713   kartoza/django_react_base:dev   \"celery -A core work\u2026\"   45 seconds ago   Up 44 seconds             22/tcp, 8080/tcp                                                                       django_react_base-worker-1\nb3c750fd3dd4   kartoza/postgis:17-3.5          \"/bin/bash /scripts/\u2026\"   45 seconds ago   Up 44 seconds             5432/tcp                                                                               django_react_base-db-1\nb9c611b040b1   kartoza/django_react_base:dev   \"sh -c 'npm install \u2026\"   45 seconds ago   Up 44 seconds (healthy)   22/tcp, 8080/tcp, 0.0.0.0:9000-&gt;9000/tcp, [::]:9000-&gt;9000/tcp                          django_react_base-webpack-1\n40f85b703342   bitnamilegacy/redis:8.2.1       \"/opt/bitnami/script\u2026\"   45 seconds ago   Up 44 seconds             6379/tcp                                                                               django_react_base-redis-1\n</code></pre> <p>List only the ID's of django_react_base docker containers:</p> <pre><code>docker ps -a | grep django_react_base | awk '{print $1}'\n</code></pre> <p>Example output:</p> <pre><code>ca145b57a7f7\n2787af751713\nb3c750fd3dd4\nb9c611b040b1\n40f85b703342\n</code></pre> <p>To kill all django_react_base docker containers:</p> <pre><code>docker kill $(docker ps -a | grep django_react_base | awk '{print $1}')\n</code></pre> <p>Example output:</p> <pre><code>ca145b57a7f7\n2787af751713\nb3c750fd3dd4\nb9c611b040b1\n40f85b703342\n</code></pre> <p>To remove all django_react_base docker containers:</p> <pre><code>docker rm $(docker ps -a | grep django_react_base | awk '{print $1}')\n</code></pre> <p>Example output:</p> <pre><code>ca145b57a7f7\n2787af751713\nb3c750fd3dd4\nb9c611b040b1\n40f85b703342\n</code></pre> <p>Verification that everything is removed:</p> <pre><code>docker ps -a | grep django_react_base\n</code></pre> <p>Example output:</p> <pre><code>\n</code></pre>"},{"location":"developer/django/setup/setup-generic/run/","title":"Django React Base","text":""},{"location":"developer/django/setup/setup-generic/run/#run-the-project","title":"Run the project","text":"<p>\ud83e\udea7 Now that the codebase is set up, you are ready to run the application.</p> <ul> <li>Run with VSCode: Guide how to run if you are using VS Code.</li> <li>Run without IDE: Guide how to run if you are not using an IDE (or using an IDE other than VSCode). Note: With this approach, you won\u2019t have access to integrated debugging features that we describe for VSCode, you will need to configure this yourself.</li> </ul>"},{"location":"developer/django/setup/setup-generic/run/run-with-vscode/","title":"Django React Base","text":""},{"location":"developer/django/setup/setup-generic/run/run-with-vscode/#vscode-launch-script","title":"VSCode Launch Script","text":"<p>When you use the <code>./vscode.sh</code> launch script, it will help you install all of necessary VSCode extensions, as well as open the project in VSCode.</p> <p>If the code CLI is already installed, you can run</p> <pre><code>./vscode.sh\n</code></pre> <p>This will install any needed extensions and launch vscode. Wait until the process is done...</p> <p>\u2b50\ufe0f Note: The first time you run the script, you will need to close the VSCode window that opens, and then run the script again. This is because the script will install the necessary extensions, and then you need to reopen VSCode to apply them.</p>"},{"location":"developer/django/setup/setup-generic/run/run-with-vscode/#building-the-dev-environment","title":"Building the dev environment","text":"<p>When you open VSCode the second time, a pop up (see below) will appear asking you if you want to re-open the project in a dev container. Simply click on this option, and it will automatically build the development containers for you.</p> <p></p> <p>\ud83d\udea7 If no \"Reopen in container\" popup appears automatically, you can initiate the process manually by checking No Reopen in container shows guide.</p> <p>So what happens when you run the project in a dev container? The script will do the following:</p> <ol> <li>Rebuild the dev container and mount your code tree inside the (docker) container.</li> <li>Install all the necessary Python dependencies inside the container.</li> <li>Set up port forwarding so that you can access the application running inside the container from your host machine.</li> <li>Start the Django development server inside the container.</li> </ol> <p>Once you click on the \"Reopen in container\" option, VSCode will start building the dev container. You can see the progress in the terminal window that opens up.</p> <p>Once the task is running, a notification 1\ufe0f\u20e3 will be shown in the bottom right of the VSCode window. Clicking in the notification will show you the setup progress 2\ufe0f\u20e3. Note that this make take quite a while depending on the internet bandwidth you have and the CPU power of your machine.</p> <p></p> <p>At the end of this process, you will see a message like this:</p> <pre><code>[229365 ms] Port forwarding 53251 &gt; 46727 &gt; 46727 terminated with code 0 and signal null.\n</code></pre> <p>Once you see that, you can continue the next step below.</p> <p>\ud83d\udea9 Note: The Port forwarding can change everytime you deploy. As long as it says <code>terminated with code 0 and signal null</code>, you are done and can continue to next step.</p>"},{"location":"developer/django/setup/setup-generic/run/run-with-vscode/#run-application","title":"Run application","text":"<p>After completing the steps above, You need to run the app.</p> <p>Click the <code>Run and Debug</code> button 1\ufe0f\u20e3 and then select <code>Django: Run server</code> 2\ufe0f\u20e3. After it is selected, click <code>Start Debugging</code> 3\ufe0f\u20e3.</p> <p></p> <p>After running, it will a new tab in the bottom right of the VSCode window. You need to wait for the Python debug to finish starting by saying <code>Quit the server with CONTROL-C.</code>3\ufe0f\u20e3,</p> <p></p>"},{"location":"developer/django/setup/setup-generic/run/run-with-vscode/#viewing-your-test-instance","title":"Viewing your test instance","text":"<p>After completing the steps above, you should have the development server available.</p> <p>Just ctrl + click the url link <code>0.0.0.0:8080</code> and click <code>Open</code></p> <p> </p> <p>\u2b50\ufe0f Note: On macOS, this will show a blank page because VSCode copies using 0.0.0.0:2000, which does not work on macOS. You can manually access it at http://localhost:2000.</p> <p>Or you can access your server directly on port 2000 of your local host:</p> <pre><code>http://localhost:8000\n</code></pre> <p></p> <p>The site will be rather bare bones since it will need to be configured in the admin area to set up the theme etc.</p> <p>By Default, we can use the admin credential:</p> <pre><code>username : admin\npassword : admin\n</code></pre> <p>\ud83e\udea7 Now that the application is set up, you may begin making updates.</p>"},{"location":"developer/django/setup/setup-generic/run/run-with-vscode/#troubleshooting","title":"Troubleshooting","text":""},{"location":"developer/django/setup/setup-generic/run/run-with-vscode/#no-code-cli-found","title":"No code CLI found","text":"<p>If the VSCode cli check fails, you can try to install VSCode manually.</p>"},{"location":"developer/django/setup/setup-generic/run/run-with-vscode/#linux","title":"Linux","text":"<p>Try following the installation instructions for your distribution on the VSCode download page.</p>"},{"location":"developer/django/setup/setup-generic/run/run-with-vscode/#windows","title":"Windows","text":"<ol> <li>Open Windows VS Code</li> <li>Install the \"Remote - WSL\" extension</li> <li>Open a WSL terminal and try check again</li> </ol>"},{"location":"developer/django/setup/setup-generic/run/run-with-vscode/#macos","title":"MacOS","text":"<ol> <li>Open VS Code</li> <li>Press Cmd+Shift+P</li> <li>Type: Shell Command: Install 'code' command in PATH</li> <li>Press Enter</li> <li>This will create a symlink:</li> </ol> <pre><code>/usr/local/bin/code -&gt; /Applications/Visual\\ Studio\\ Code.app/Contents/Resources/app/bin/code\n</code></pre> <p>And try to check it again via</p> <pre><code>code --version\n</code></pre> <p>If you succeed with setup code cli, you can move to configuration.</p> <p>If you are still having trouble you can try to set up things manually.</p>"},{"location":"developer/django/setup/setup-generic/run/run-with-vscode/#installing-devcontainers-extension","title":"Installing devcontainers extension","text":"<p>You can install Dev Containers extension manually (minimum version 0.304.0).</p> <p> </p> <p></p>"},{"location":"developer/django/setup/setup-generic/run/run-with-vscode/#open-project","title":"Open project","text":"<p>Open the project in VSCode (1\ufe0f\u20e3, 2\ufe0f\u20e3) by navigating the place on your file system where you checked out the code in the pre-requisites step above (3\ufe0f\u20e3).</p> <p></p> <p>Accept the 'trust authors' prompt</p> <p></p> <p>After that everything above is done, you can move on to Building the dev environment.</p>"},{"location":"developer/django/setup/setup-generic/run/run-with-vscode/#no-reopen-in-container-shows","title":"No reopen in container shows","text":"<p>Press <code>Ctrl -&gt; P</code> 1\ufe0f\u20e3 and then <code>&gt;</code>and search for <code>Rebuild</code>. Select <code>Dev Containers: Rebuild and Reopen in Container</code>2\ufe0f\u20e3. This will essentially mount your code tree inside a docker container and switch the development context of VSCode to be inside the container where all of the python etc. dependencies will be installed.</p> <p></p> <p>\ud83e\udea7 Now that the application is set up, you may begin making updates.</p>"},{"location":"developer/django/setup/setup-generic/run/run-without-ide/","title":"Django React Base","text":""},{"location":"developer/django/setup/setup-generic/run/run-without-ide/#run-without-ide","title":"Run without IDE","text":"<p>If you're using a text editor other than an IDE (such as PyCharm, Sublime Text, or Vim), you can run the application manually from the terminal:</p> <ol> <li>Navigate to the root directory of the project.</li> <li>Open a terminal and execute the following command:</li> </ol> <pre><code>make dev\n</code></pre> <p>Note: With this approach, you won\u2019t have access to integrated debugging features provided by full IDEs.</p> <p>To verify that the development instance is running correctly, execute the following command: </p><pre><code>docker logs -f django_react_base-dev-1\n</code></pre> Allow the process to continue until the following message or indicator appears: <p></p> <p>Once this confirmation is visible, you may proceed to the next step to access your running instance.</p>"},{"location":"developer/django/setup/setup-generic/run/run-without-ide/#viewing-your-test-instance","title":"Viewing your test instance","text":"<p>After completing the steps above, you should have the development server available on port 2000 of your local host:</p> <pre><code>http://localhost:8000\n</code></pre> <p></p> <p>By Default, we can use the admin credential: </p><pre><code>username : admin\npassword : admin\n</code></pre> <p>\ud83e\udea7 Now that the application is set up, you may begin making updates.</p>"},{"location":"developer/django/setup/setup-linux/","title":"Django React Base","text":""},{"location":"developer/django/setup/setup-linux/#ubuntu-2404-ltr-setup-guide","title":"\ud83d\udc27 Ubuntu 24.04 LTR Setup Guide","text":""},{"location":"developer/django/setup/setup-linux/#vscode","title":"VSCode","text":"<p>For Ubuntu Linux, it is recommended to install it via:</p> <pre><code>sudo snap install code --classic\n</code></pre> <p>You should now have VSCode installed.</p> <p>You also need to have the code CLI available.</p> <p>To check:</p> <pre><code>code --version\n</code></pre> <p>It should return something like the output below:</p> <pre><code>1.100.2\n848b80aeb52026648a8ff9f7c45a9b0a80641e2e\nx64\n</code></pre>"},{"location":"developer/django/setup/setup-linux/#setup-docker-on-linux","title":"Setup Docker on Linux","text":"<p>In this section we cover any tools that need to be on your system so that you can have a local development environment.</p>"},{"location":"developer/django/setup/setup-linux/#docker","title":"Docker","text":"<p>We assume in our notes that you are using the current Ubuntu LTS - though we try to keep things generic so that you can repeat on other distros or WSL2 on windows.</p> <p>We recommend using the official Docker packages (not those provided by your distro) and assume membership of the docker group. See docker.io's guide for setup notes and below for adding yourself to the docker group.</p> <pre><code>sudo usermod -a -G docker $user\n</code></pre> <p>(Restart your computer after making this change)</p> <p>You need to have docker-compose installed - version 1.29 or later should work fine.</p> <p></p>"},{"location":"developer/django/setup/setup-linux/#dependencies-installation","title":"Dependencies installation","text":"<p>The project provide make command that making setup process easier. To install make on your machine or virtual box server, do:</p> <pre><code>sudo apt install make\n</code></pre> <p>Project has recipe that you can use to run the project in one command. This recipe needs docker-compose to be able to use it. To install it, do:</p> <pre><code>sudo apt install docker-compose\napt install ca-certificates curl gnup lsb-release  \n</code></pre>"},{"location":"developer/django/setup/setup-linux/#docker-installation","title":"Docker installation","text":"<p>The project needs docker to be able to run it. To install docker, please follow these instructions.</p> <pre><code>curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg     \n</code></pre> <p>On the next prompt line:</p> <pre><code>echo \\\n\"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg]https:download.docker.com/linux/ubuntu \\\n$(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n</code></pre> <p>Run apt update:</p> <pre><code>sudo apt-get update\n</code></pre> <p>This will install docker</p> <pre><code>sudo apt-get install  docker-ce-cli containerd.io\n</code></pre> <p>This will check if installation of docker was successful</p> <pre><code>sudo docker version\n</code></pre> <p>And it should return like this</p> <pre><code>Client: Docker Engine - Community\n Version:           20.10.9\n API version:       1.41\n Go version:        go1.16.8\n Git commit:        c2ea9bc\n Built:             Mon Oct  4 16:08:29 2021\n OS/Arch:           linux/amd64\n Context:           default\n Experimental:      true\n</code></pre>"},{"location":"developer/django/setup/setup-linux/#manage-docker-as-non-root","title":"Manage docker as non-root","text":"<p>This will ensure that the docker can be executed without sudo.</p> <pre><code>sudo systemctl daemon-reload\nsudo systemctl start docker\nsudo usermod -a -G $USER\nsudo systemctl enable docker\n</code></pre> <p>Verify that you can run docker commands without sudo.</p> <pre><code>docker run hello-world\n</code></pre> <p>For more information how to install docker, please visit Install Docker Engine</p>"},{"location":"developer/django/setup/setup-linux/#git","title":"Git","text":"<p>Make sure you have Git installed.</p>"},{"location":"developer/django/setup/setup-linux/#next-steps","title":"Next Steps","text":"<p>\ud83e\udea7 Now that you have the docker, move on to the generic workflow, starting with Cloning.</p>"},{"location":"developer/django/setup/setup-mac/","title":"Django React Base","text":""},{"location":"developer/django/setup/setup-mac/#macos-setup-guide","title":"macOS Setup Guide","text":""},{"location":"developer/django/setup/setup-mac/#vscode","title":"VSCode","text":"<p>For macOS it is recommended to fetch and install VSCode from the VSCode home page.</p> <p>You also need to have the code CLI available. To do this, open VSCode, go to the Command Palette (Cmd+Shift+P), and type <code>Shell Command: Install 'code' command in PATH</code>. This will allow you to run <code>code</code> from the terminal.</p> <p>To check:</p> <pre><code>code --version\n</code></pre> <p>It should return something like the output below:</p> <pre><code>1.100.2\n848b80aeb52026648a8ff9f7c45a9b0a80641e2e\narm64\n</code></pre>"},{"location":"developer/django/setup/setup-mac/#setup-docker-on-macos","title":"Setup Docker on macOS","text":"<p>We recommend using the official Docker Desktop application. See docker website for setup tools.</p> <p>\u2b50\ufe0f Note: If you are using an arm based Mac (M1, M2, M3 etc.), you will need to ensure that you download the version of Docker Desktop that is compatible with Apple Silicon.</p> <p>At the end of the installation, you should have a working Docker Desktop application. You can verify this by running:</p> <pre><code>docker --version\n</code></pre>"},{"location":"developer/django/setup/setup-mac/#homebrew","title":"Homebrew","text":"<p>Make sure you have Homebrew installed. If not, you can install it by running:</p> <pre><code>/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n</code></pre> <p>Follow the on-screen instructions. After installation, you may need to add Homebrew to your shell profile (.zprofile, .zshrc, etc.).</p>"},{"location":"developer/django/setup/setup-mac/#jq","title":"\u2705 jq","text":"<p>jq is a command-line JSON processor.</p> <pre><code>brew install jq\n</code></pre> <p>Verify:</p> <pre><code>jq --version\n</code></pre>"},{"location":"developer/django/setup/setup-mac/#make","title":"\u2705 make","text":"<p>Make is a build automation tool that is used to manage dependencies and automate the build process.</p> <pre><code>brew install make\n</code></pre>"},{"location":"developer/django/setup/setup-mac/#git","title":"Git","text":"<p>brew install git</p>"},{"location":"developer/django/setup/setup-mac/#recommended","title":"Recommended","text":"<p>If you want to share changes upstream to the repo, you should sign your commits. See the GitHub Documentation on this topic to see how to prepare your system for this.</p>"},{"location":"developer/django/setup/setup-mac/#next-steps","title":"Next Steps","text":"<p>\ud83e\udea7 Now that you have the docker, move on to the generic workflow, starting with Cloning.</p>"},{"location":"developer/django/setup/setup-win/","title":"Django React Base","text":"<p>For windows development setup, we will use WSL2 (Windows Subsystem for Linux) to run the development environment. This allows us to run a Linux distribution on Windows, which is more compatible with the tools and libraries used in django application.</p>"},{"location":"developer/django/setup/setup-win/#wsl2","title":"WSL2","text":"<p>WSL2 is needed to run linux environment in Windows. Follow step by step below to install WSL2.</p> <p>Open Powershell as Administrator</p> <p></p> <p>Install wsl2 with below command</p> <pre><code>wsl --install\n</code></pre> <p></p> <p>Once completed, you need to restart the machine. You can check if the installation is completed successfully by checking the list of installed distribution from the Powershell.</p> <pre><code>wsl --list\n</code></pre> <p>By default, the Ubuntu is chosen and installed after running the first command. However if there is no distribution that is installed like image below, we can then install it manually.</p> <p></p> <p>To list all the available distribution, we can run command:</p> <pre><code>wsl --list --online\n</code></pre> <p>The results:</p> <pre><code>The following is a list of valid distributions that can be installed.\nInstall using 'wsl.exe --install &lt;Distro&gt;'.\n\nNAME                            FRIENDLY NAME\nAlmaLinux-8                     AlmaLinux OS 8\nAlmaLinux-9                     AlmaLinux OS 9\nAlmaLinux-Kitten-10             AlmaLinux OS Kitten 10\nDebian                          Debian GNU/Linux\nFedoraLinux-42                  Fedora Linux 42\nSUSE-Linux-Enterprise-15-SP5    SUSE Linux Enterprise 15 SP5\nSUSE-Linux-Enterprise-15-SP6    SUSE Linux Enterprise 15 SP6\nUbuntu                          Ubuntu\nUbuntu-24.04                    Ubuntu 24.04 LTS\narchlinux                       Arch Linux\nkali-linux                      Kali Linux Rolling\nopenSUSE-Tumbleweed             openSUSE Tumbleweed\nopenSUSE-Leap-15.6              openSUSE Leap 15.6\nUbuntu-18.04                    Ubuntu 18.04 LTS\nUbuntu-20.04                    Ubuntu 20.04 LTS\nUbuntu-22.04                    Ubuntu 22.04 LTS\nOracleLinux_7_9                 Oracle Linux 7.9\nOracleLinux_8_7                 Oracle Linux 8.7\nOracleLinux_9_1                 Oracle Linux 9.1\n</code></pre> <p>We will use the latest Ubuntu version, 24.04 LTS. To install it, run command:</p> <pre><code>wsl --install Ubuntu-24.04\n</code></pre> <p></p> <p>Once ubuntu is installed, we can setup the user account for Ubuntu. Search for ubuntu from the search bar and click Open to run it.</p> <p></p> <p>It will open a terminal where you can setup username and password for your Ubuntu.</p> <p></p> <p>After your user account is created, you will see below image that indicates the installation is successful.</p> <p></p> <p>You should update your system after this by running command:</p> <pre><code>sudo apt-get update &amp;&amp; sudo apt-get upgrade\n</code></pre>"},{"location":"developer/django/setup/setup-win/#install-git","title":"Install Git","text":"<pre><code>sudo apt-get install git\n</code></pre>"},{"location":"developer/django/setup/setup-win/#optional-ssh-setup","title":"(Optional) SSH Setup","text":"<p>The SSH are preferred when fetching and pushing codes to GitHub. Please follow this link to generate SSH key pair and add it into your GitHub account.</p>"},{"location":"developer/django/setup/setup-win/#optional-gpg-setup","title":"(Optional) GPG Setup","text":"<p>GPG signing keys are used to sign the commits. WSL2 can use the keys from Windows by following this tutorial. Next, we need to update the configuration inside WSL2, edit or create if this file does not exist: <code>~/.gnupg/gpg-agent.conf</code>.</p> <pre><code>default-cache-ttl 34560000\nmax-cache-ttl 34560000\npinentry-program \"/mnt/c/Program Files (x86)/GnuPG/bin/pinentry-basic.exe\"\n</code></pre> <p>It is recommended to explicitly restart the gpg agent to force these changes. Alternatively, restart Windows at this point.</p> <pre><code>gpgconf --kill gpg-agent\n</code></pre> <p>Once the key is generated, please follow this link to add it into your GitHub account.</p>"},{"location":"developer/django/setup/setup-win/#docker-setup","title":"Docker Setup","text":"<p>Follow this guide to install docker desktop that integrates with WSL2. After docker is installed and running, we recommend to disable the <code>Resource Saver</code> feature as it may cause unexpected issue during development.</p> <p></p>"},{"location":"developer/django/setup/setup-win/#install-vscode","title":"Install VSCode","text":"<p>Follow the installation steps from this link to setup the VSCode on Windows. The VSCode CLI will also be installed in the WSL2 and you can check by running below command in the WSL2 Ubuntu terminal.</p> <pre><code>code --version\n</code></pre> <p>It will return output like below:</p> <pre><code>1.100.2\n848b80aeb52026648a8ff9f7c45a9b0a80641e2e\nx64\n</code></pre>"},{"location":"developer/django/setup/setup-win/#next-steps","title":"Next Steps","text":"<p>\ud83e\udea7 Now that you have the docker, move on to the generic workflow, starting with Cloning.</p>"},{"location":"developer/geoparquet/","title":"Documentation","text":""},{"location":"developer/geoparquet/#gap-geoparquet-products","title":"GAP GeoParquet Products","text":"<p>The TomorrowNow GAP platform publishes processed products as GeoParquet files in the object storage bucket. These datasets can be queried directly using DuckDB, Dask, or other parquet-compatible libraries.</p>"},{"location":"developer/geoparquet/#available-products","title":"Available Products","text":"<ul> <li> <p>SPW   Standard Planting Window dataset. Provides daily and seasonal planting recommendations for farmers.</p> </li> <li> <p>SPW Tamsat   Variant of SPW dataset using TAMSAT rainfall estimates.</p> </li> <li> <p>DCAS   Dynamic Crop Advisory System outputs combining crop models, GDD thresholds, and registry data.</p> </li> </ul>"},{"location":"developer/geoparquet/#next-steps","title":"Next Steps","text":"<p>For each product you will find:</p> <ol> <li>Pre-requisites \u2014 setting up S3 credentials and DuckDB access.  </li> <li>Column Descriptions \u2014 schema and meaning of each field.  </li> <li>Example Queries \u2014 how to query GeoParquet files for specific use cases.</li> </ol>"},{"location":"developer/geoparquet/dcas/","title":"Documentation","text":""},{"location":"developer/geoparquet/dcas/#dcas-geoparquet","title":"DCAS GeoParquet","text":"<p>The Dynamic Crop Advisory System (DCAS) dataset provides daily crop advice, growth-stage monitoring, and climate-related metrics. It is stored as partitioned GeoParquet files in the GAP bucket.</p>"},{"location":"developer/geoparquet/dcas/#prerequisites","title":"Prerequisites","text":"<p>Python 3.9+ DuckDB with extensions:</p> <ul> <li><code>httpfs</code> (S3/HTTP access)  </li> <li><code>spatial</code> (GEOMETRY support)  </li> </ul> <p>Read-only GAP object storage credentials</p>"},{"location":"developer/geoparquet/dcas/#environment-variables","title":"Environment variables","text":"<pre><code>export S3_ENDPOINT_URL=\"https://fra1.digitaloceanspaces.com\"\nexport S3_ACCESS_KEY_ID=\"YOUR_READ_ONLY_KEY\"\nexport S3_SECRET_ACCESS_KEY=\"YOUR_READ_ONLY_SECRET\"\nexport S3_BUCKET_NAME=\"bucket-name\"\n</code></pre>"},{"location":"developer/geoparquet/dcas/#path-layout","title":"Path layout","text":"<p>DCAS is partitioned by country (iso_a3), year, month, and day:</p> <pre><code>s3://$S3_BUCKET_NAME/staging/dcas_output/iso_a3=KEN/year=/month=/day=*/*.parquet\n</code></pre> <p>Example:</p> <pre><code>s3://gap-products/staging/dcas_output/iso_a3=KEN/year=2025/month=9/day=10/*.parquet\n</code></pre> <p>Always pass <code>hive_partitioning=true</code> to make iso_a3, year, month, and day available as columns.</p>"},{"location":"developer/geoparquet/dcas/#column-descriptions","title":"Column descriptions","text":"<p>The following columns are available in DCAS GeoParquet.  </p> Column name Type Description <code>planting_date_epoch</code> UINTEGER Epoch timestamp of planting date for the farm. <code>crop_id</code> USMALLINT Numeric identifier of the crop type. <code>crop_stage_type_id</code> USMALLINT Identifier for the type of growth stage. <code>group_id</code> UINTEGER Internal group identifier. <code>farm_id</code> BIGINT Internal numeric farm identifier. <code>farm_unique_id</code> VARCHAR External farm identifier (used for joining/filtering). <code>geometry</code> GEOMETRY Spatial geometry of the farm/grid (polygon or point). <code>grid_id</code> UINTEGER Numeric identifier for grid cell. <code>grid_unique_id</code> VARCHAR Unique identifier for grid cell. <code>registry_id</code> BIGINT Identifier from farm registry. <code>crop</code> VARCHAR Crop name (e.g. \u201cmaize\u201d). <code>country_id</code> UINTEGER Country identifier (numeric). <code>grid_crop_key</code> VARCHAR Composite key linking grid and crop. <code>county</code> VARCHAR County name (administrative boundary). <code>subcounty</code> VARCHAR Subcounty name (administrative boundary). <code>ward</code> VARCHAR Ward name (administrative boundary). <code>preferred_language</code> VARCHAR Preferred language for communication/advisories. <code>date</code> TIMESTAMP Record timestamp. <code>prev_growth_stage_id</code> USMALLINT Previous growth stage identifier. <code>prev_growth_stage_start_date</code> UINTEGER Epoch timestamp when previous growth stage started. <code>config_id</code> USMALLINT Identifier for model/config version used. <code>growth_stage_start_date</code> UINTEGER Epoch timestamp when current growth stage started. <code>growth_stage_id</code> USMALLINT Identifier for current growth stage. <code>total_gdd</code> DOUBLE Accumulated Growing Degree Days (GDD). <code>seasonal_precipitation</code> DOUBLE Total precipitation recorded in current season (mm). <code>temperature</code> DOUBLE Mean temperature for record period (\u00b0C). <code>humidity</code> DOUBLE Mean relative humidity (%) for record period. <code>p_pet</code> DOUBLE Precipitation / Potential Evapotranspiration ratio. <code>growth_stage_precipitation</code> DOUBLE Precipitation during current growth stage (mm). <code>message</code> UINTEGER Encoded advisory message ID. <code>message_2</code> UINTEGER Secondary message code (if available). <code>message_3</code> UINTEGER Tertiary message code. <code>message_4</code> UINTEGER Quaternary message code. <code>message_5</code> UINTEGER Quinary message code. <code>is_empty_message</code> VARCHAR Flag if message is empty (text flag). <code>has_repetitive_message</code> VARCHAR Flag if advisory is repetitive (text flag). <code>final_message</code> UINTEGER Final consolidated advisory message ID. <code>prev_week_message</code> UINTEGER Advisory message from the previous week. <code>growth_stage</code> VARCHAR Human-readable crop growth stage name. <code>__null_dask_index__</code> BIGINT Index column generated by Dask (ignore in most queries). <code>day</code> BIGINT Day partition (from file path). <code>iso_a3</code> VARCHAR ISO Alpha-3 country code (e.g. KEN). <code>month</code> BIGINT Month partition (from file path). <code>year</code> BIGINT Year partition (from file path)."},{"location":"developer/geoparquet/dcas/#example-queries","title":"Example queries","text":""},{"location":"developer/geoparquet/dcas/#stage-a-subset","title":"Stage a subset","text":"<pre><code>import os, duckdb\n\nconn = duckdb.connect()\nconn.install_extension(\"httpfs\"); conn.load_extension(\"httpfs\")\nconn.install_extension(\"spatial\"); conn.load_extension(\"spatial\")\n\ndcas_path = (\n  f\"s3://{os.environ['S3_BUCKET_NAME']}/\"\n  \"staging/dcas_output/iso_a3=KEN/year=*/month=*/day=*/*.parquet\"\n)\n\nconn.sql(f\"\"\"\nCREATE OR REPLACE TABLE dcas AS\nSELECT *\nFROM read_parquet('{dcas_path}', hive_partitioning=true)\nWHERE year=2025 AND month=9 AND day=10\n\"\"\")\n</code></pre>"},{"location":"developer/geoparquet/dcas/#quick-checks","title":"Quick checks","text":"<pre><code>-- Count rows\nSELECT COUNT(*) FROM dcas;\n\n-- Schema overview\nDESCRIBE dcas;\n</code></pre>"},{"location":"developer/geoparquet/dcas/#distinct-messages","title":"Distinct messages","text":"<pre><code>SELECT DISTINCT final_message FROM dcas;\n</code></pre>"},{"location":"developer/geoparquet/dcas/#messages-distribution","title":"Messages distribution","text":"<pre><code>SELECT final_message, COUNT(*) AS n\nFROM dcas\nGROUP BY final_message\nORDER BY n DESC;\n</code></pre>"},{"location":"developer/geoparquet/dcas/#per-farm-history","title":"Per-farm history","text":"<pre><code>SELECT date, farm_unique_id, crop, growth_stage, final_message\nFROM dcas\nWHERE farm_unique_id = '4023361'\nORDER BY date DESC\nLIMIT 20;\n</code></pre>"},{"location":"developer/geoparquet/spw-tamsat/","title":"Documentation","text":""},{"location":"developer/geoparquet/spw-tamsat/#spw-tamsat-geoparquet","title":"SPW Tamsat GeoParquet","text":"<p>The SPW Tamsat dataset is a variant of the Standard Planting Window (SPW) product generated using TAMSAT rainfall estimates. Data is stored as partitioned GeoParquet files in the GAP bucket.</p>"},{"location":"developer/geoparquet/spw-tamsat/#prerequisites","title":"Prerequisites","text":"<p>Same as SPW.</p> <p>Python 3.9+</p> <p>DuckDB with: <code>httpfs</code> and <code>spatial</code> extensions</p> <p>Read-only object storage credentials (<code>S3_ENDPOINT_URL</code>, <code>S3_ACCESS_KEY_ID</code>, <code>S3_SECRET_ACCESS_KEY</code>, <code>S3_BUCKET_NAME</code>)</p>"},{"location":"developer/geoparquet/spw-tamsat/#path-layout","title":"Path layout","text":"<p>Partitioned by year and month:</p> <pre><code>s3://$S3_BUCKET_NAME/staging/tamsat_spw_geoparquet/year=/month=.parquet\n</code></pre> <p>Example:</p> <pre><code>s3://gap-products/staging/tamsat_spw_geoparquet/year=2025/month=9.parquet\n</code></pre>"},{"location":"developer/geoparquet/spw-tamsat/#column-descriptions","title":"Column descriptions","text":"<p>Observed schema (from <code>DESCRIBE SELECT * FROM read_parquet(... ) LIMIT 1</code>):</p> # Column name Type Description 0 <code>date</code> DATE Record date for the daily TAMSAT-SPW output. 1 <code>farm_id</code> BIGINT Internal numeric farm identifier. 2 <code>farm_unique_id</code> VARCHAR External farm identifier used for joins/filters. 3 <code>country</code> VARCHAR Country name. 4 <code>farm_group_id</code> BIGINT Internal group identifier. 5 <code>farm_group</code> VARCHAR Farm group label (e.g., \u201cKALRO 2025 A\u201d). 6 <code>grid_id</code> BIGINT Numeric grid identifier. 7 <code>grid_unique_id</code> VARCHAR Unique grid identifier. 8 <code>geometry</code> GEOMETRY Farm/grid geometry (polygon/point). 9 <code>latitude</code> DOUBLE Latitude of farm/grid centroid. 10 <code>longitude</code> DOUBLE Longitude of farm/grid centroid. 11 <code>sm_25</code> DOUBLE Soil moisture proxy/indicator at 25th percentile (TAMSAT-derived workflow). 12 <code>sm_50</code> DOUBLE Soil moisture proxy/indicator at 50th percentile. 13 <code>sm_70</code> DOUBLE Soil moisture proxy/indicator at 70th percentile. 14 <code>spw_20</code> DOUBLE SPW decision score at 20% threshold scenario. 15 <code>spw_40</code> DOUBLE SPW decision score at 40% threshold scenario. 16 <code>spw_60</code> DOUBLE SPW decision score at 60% threshold scenario. 17 <code>pfc_user_probability</code> DOUBLE User/algorithm probability for PFC (Planting Feasibility Criteria). 18 <code>wrsi_user_probability</code> DOUBLE User/algorithm probability for WRSI (Water Requirement Satisfaction Index). 19 <code>pfc_user_decision</code> DOUBLE Decision value derived from PFC probability. 20 <code>wrsi_user_decision</code> DOUBLE Decision value derived from WRSI probability. 21 <code>sm_user_decision</code> DOUBLE Decision contribution from soil moisture indicator(s). 22 <code>pfc_thresh</code> DOUBLE Threshold applied for PFC decisioning. 23 <code>pfc_prob_thresh</code> DOUBLE Probability threshold applied for PFC. 24 <code>wrsi_thresh_factor</code> DOUBLE Factor used in WRSI thresholding. 25 <code>wrsi_prob_thresh</code> DOUBLE Probability threshold applied for WRSI. 26 <code>year</code> BIGINT Partition year (from folder structure). <p>Notes: - <code>sm_*</code> and <code>spw_*</code> fields capture soil-moisture and scenario-specific SPW indicators derived from TAMSAT inputs. - Partition columns (<code>year</code> via hive partitioning; month is in the path) should be used for performant queries.</p>"},{"location":"developer/geoparquet/spw-tamsat/#example-queries","title":"Example queries","text":""},{"location":"developer/geoparquet/spw-tamsat/#filter-by-date","title":"Filter by date","text":"<pre><code>SELECT date, farm_unique_id, spw_20, spw_40, spw_60,\n       pfc_user_probability, wrsi_user_probability\nFROM read_parquet(\n  's3://gap-products/staging/tamsat_spw_geoparquet/year=2025/month=9.parquet',\n  hive_partitioning=true\n)\nWHERE date = DATE '2025-09-10'\nLIMIT 20;\n</code></pre>"},{"location":"developer/geoparquet/spw-tamsat/#filter-by-farm","title":"Filter by farm","text":"<pre><code>import os, duckdb\nconn = duckdb.connect()\nconn.install_extension(\"httpfs\"); conn.load_extension(\"httpfs\")\nconn.install_extension(\"spatial\"); conn.load_extension(\"spatial\")\n\nfarm_unique_id = '4023361'\npath = (\n  f\"s3://{os.environ['S3_BUCKET_NAME']}/\"\n  \"staging/tamsat_spw_geoparquet/year=2025/month=9.parquet\"\n)\n\nconn.sql(f\"\"\"\nCREATE OR REPLACE TABLE spw_tamsat AS\nSELECT *\nFROM read_parquet('{path}', hive_partitioning=true)\nWHERE date BETWEEN '2025-09-05' AND '2025-09-10'\n\"\"\")\n\nconn.sql(f\"\"\"\nSELECT date, farm_unique_id,\n       spw_20, spw_40, spw_60,\n       pfc_user_probability, wrsi_user_probability,\n       pfc_user_decision, wrsi_user_decision, sm_user_decision\nFROM spw_tamsat\nWHERE farm_unique_id = '{farm_unique_id}'\nORDER BY date DESC\n\"\"\").show()\n</code></pre>"},{"location":"developer/geoparquet/spw/","title":"Documentation","text":""},{"location":"developer/geoparquet/spw/#spw-geoparquet","title":"SPW GeoParquet","text":"<p>The Standard Planting Window (SPW) dataset provides daily planting recommendations and related indicators for each farm/grid. Data is stored as partitioned GeoParquet files in the GAP bucket.</p>"},{"location":"developer/geoparquet/spw/#prerequisites","title":"Prerequisites","text":"<p>Python 3.9+ DuckDB with extensions:</p> <ul> <li><code>httpfs</code> (S3/HTTP access)</li> <li><code>spatial</code> (GEOMETRY support)</li> </ul> <p>Read-only GAP object storage credentials</p>"},{"location":"developer/geoparquet/spw/#environment-variables","title":"Environment variables","text":"<pre><code>export S3_ENDPOINT_URL=\"https://fra1.digitaloceanspaces.com\"\nexport S3_ACCESS_KEY_ID=\"YOUR_READ_ONLY_KEY\"\nexport S3_SECRET_ACCESS_KEY=\"YOUR_READ_ONLY_SECRET\"\nexport S3_BUCKET_NAME=\"bucket-name\"\n</code></pre>"},{"location":"developer/geoparquet/spw/#path-layout","title":"Path layout","text":"<p>SPW is partitioned by year and month:</p> <pre><code>s3://$S3_BUCKET_NAME/staging/spw_geoparquet/year=/month=.parquet\n</code></pre> <p>An example would be:</p> <pre><code>s3://gap-products/staging/spw_geoparquet/year=2025/month=9.parquet\n</code></pre> <p>Always pass hive_partitioning=true to include partition columns.</p>"},{"location":"developer/geoparquet/spw/#column-descriptions","title":"Column descriptions","text":"Column Type Description <code>date</code> DATE Record date <code>year</code> INT Partition year <code>farm_id</code> BIGINT Internal numeric farm id <code>farm_unique_id</code> VARCHAR External farm identifier <code>country</code> VARCHAR Country name <code>farm_group</code> VARCHAR Farm group (e.g. \u201cKALRO 2025 A\u201d) <code>farm_group_id</code> BIGINT Group identifier <code>grid_id</code> BIGINT Numeric grid identifier <code>grid_unique_id</code> VARCHAR Unique grid identifier <code>geometry</code> GEOMETRY Farm/grid geometry <code>signal</code> VARCHAR Decision signal (e.g. \u201cDo NOT plant, DRY Tier 4b\u201d) <code>last_2_days</code> DOUBLE Rainfall/indicator over last 2 days <code>last_4_days</code> DOUBLE Rainfall/indicator over last 4 days <code>today_tomorrow</code> DOUBLE Forecast indicator for today + tomorrow <code>too_wet_indicator</code> VARCHAR Text category (e.g. \u201cNot too wet to plant\u201d)"},{"location":"developer/geoparquet/spw/#example-queries","title":"Example queries","text":""},{"location":"developer/geoparquet/spw/#filter-by-date","title":"Filter by date","text":"<pre><code>from datetime import date\nimport os, duckdb\n\nconn = duckdb.connect()\nconn.install_extension(\"httpfs\"); conn.load_extension(\"httpfs\")\nconn.install_extension(\"spatial\"); conn.load_extension(\"spatial\")\n\nspw_date = date.fromisoformat(\"2025-09-10\")\nspw_path = (\n  f\"s3://{os.environ['S3_BUCKET_NAME']}/\"\n  f\"staging/spw_geoparquet/year={spw_date.year}/month={spw_date.month}.parquet\"\n)\n\nq = f\"\"\"\nSELECT *\nFROM read_parquet('{spw_path}', hive_partitioning=true)\nWHERE date = '{spw_date}'\nLIMIT 10;\n\"\"\"\nconn.sql(q).show()\n</code></pre>"},{"location":"developer/geoparquet/spw/#filter-by-farm_unique_id","title":"Filter by farm_unique_id","text":"<pre><code>farm_unique_id = '4023361'\n\nconn.sql(f\"\"\"\nCREATE OR REPLACE TABLE spw_geoparquet AS\nSELECT *\nFROM read_parquet('{spw_path}', hive_partitioning=true)\nWHERE date BETWEEN '2025-09-05' AND '2025-09-10'\n\"\"\")\n\nconn.sql(f\"\"\"\nSELECT date, farm_unique_id, farm_group, signal, too_wet_indicator\nFROM spw_geoparquet\nWHERE farm_unique_id = '{farm_unique_id}'\nORDER BY date DESC\n\"\"\").show()\n</code></pre>"},{"location":"developer/geoparquet/spw/#export-to-csv","title":"Export to CSV","text":"<pre><code>import os\nos.makedirs(\"output_csv\", exist_ok=True)\n\nexport_q = f\"\"\"\nSELECT *\nFROM spw_geoparquet\nWHERE farm_unique_id = '{farm_unique_id}'\n\"\"\"\nconn.sql(f\"COPY ({export_q}) TO 'output_csv/spw_geoparquet_{farm_unique_id}.csv' (HEADER, DELIMITER ',');\")\n</code></pre>"},{"location":"devops/","title":"TomorrowNow - Global Access Platform (GAP)","text":""},{"location":"devops/#devops-documentation","title":"DevOps documentation","text":"<p>This section contains all documentation relevant to DevOps procedures.</p> <p>The devops content is divided into two sections:</p> <ul> <li>The devops guide, which describes common workflows for deployment and management of running instances in a tutorial format.</li> <li>The devops manual, which provides links and references to deployment configuration files, frameworks and deployment systems used etc.</li> <li>The migration, which touches on migration from MinIO to DigitalOcean Spaces.</li> </ul>"},{"location":"devops/guide/","title":"TomorrowNow - Global Access Platform (GAP)","text":""},{"location":"devops/guide/#devops-guide","title":"DevOps guide","text":""},{"location":"devops/manual/","title":"TomorrowNow - Global Access Platform (GAP)","text":""},{"location":"devops/manual/#devops-documentation","title":"DevOps documentation","text":""},{"location":"devops/manual/#containers-used","title":"Containers used","text":""},{"location":"devops/manual/#sdlc","title":"SDLC","text":""},{"location":"devops/manual/#continuous-integration","title":"Continuous integration","text":""},{"location":"devops/manual/#testing-deployments","title":"Testing deployments","text":""},{"location":"devops/manual/#backend-orchestration","title":"Backend orchestration","text":""},{"location":"devops/manual/#deployments","title":"Deployments","text":""},{"location":"devops/manual/#kubernetes","title":"Kubernetes","text":""},{"location":"devops/migration/","title":"Migration","text":""},{"location":"devops/migration/#migration-from-minio-to-digitalocean-spaces","title":"Migration from MinIO to DigitalOcean Spaces","text":""},{"location":"devops/migration/#data-migration-effort-and-time","title":"Data Migration (Effort and Time)","text":""},{"location":"devops/migration/#scope-key-questions","title":"Scope &amp; Key Questions","text":"<p>Scope Definition:</p> <ul> <li>Is the migration limited to the TNGAP products bucket?</li> <li>Are we dealing exclusively with static files, or do any of the files undergo frequent updates requiring minimal disruption?</li> </ul> <p>Timing:</p> <ul> <li>When can the migration be executed to avoid conflicts with active CRUD operations?</li> </ul> <p>Metadata &amp; Versioning:</p> <ul> <li>Is it necessary to retain version history or metadata (e.g., tags, last-modified timestamps)?</li> <li>This is a critical consideration, as tools like <code>mc mirror</code> do not preserve versioning or metadata.</li> </ul>"},{"location":"devops/migration/#approach-options","title":"Approach Options","text":"<p>Option 1: <code>mc mirror</code> (Recommended for simplicity and efficiency)</p> <ul> <li>Advantages:<ul> <li>Fast and suitable for one-way mirroring.</li> <li>Simple to script and automate.</li> <li>Effective across S3-compatible endpoints with differing credentials.</li> </ul> </li> <li>Limitations:<ul> <li>Does not preserve version history or bucket-level metadata (e.g., object tags, lifecycle policies).</li> </ul> </li> </ul>"},{"location":"devops/migration/#example-script","title":"Example script","text":"<p>A sample Bash script to automate the migration using <code>mc mirror</code>:</p> <pre><code>\n</code></pre> <p>Option 2: Custom scripting using <code>aws s3 sync</code> (via AWS S3 compatibility layer)</p> <ul> <li>Offers more granular control if needed.</li> <li>But DigitalOcean Spaces' AWS compatibility is partial\u2014not all SDK features work reliably.</li> </ul>"},{"location":"devops/migration/#time-effort-estimate","title":"Time &amp; Effort Estimate","text":"<p>The following estimates are based on the assumption that the only target for migration is the <code>tngap-products</code> bucket (approximately 85\u2013125 GiB as of 18-04-2024):</p> <p>Average Transfer Speed: Estimated at 30\u201350 MiB/s (dependent on network conditions).</p> <p>Migration Duration:</p> <ul> <li><code>85 GiB / 40 MiB/s \u2248 2\u20132.5 hours</code></li> <li><code>125 GiB / 40 MiB/s \u2248 3\u20133.5 hours</code></li> </ul> <p>Estimated Activity Breakdown:</p> Activity Time Estimate Creating bucket policies 1.5 hours Migrating users/groups to DO Teams 1 hour Dry-run sync 15\u201330 minutes Initial data sync 2\u20133.5 hours Final delta sync 30 minutes\u20131 hour Validating post-migration access rules 1 hour Reconfiguring TNGAP application endpoints 1\u20132 hours Post-migration monitoring 1\u20132 hours"},{"location":"devops/migration/#digitalocean-costing","title":"DigitalOcean Costing","text":""},{"location":"devops/migration/#cost-components","title":"Cost Components","text":"<p>Storage:</p> <ul> <li>$0.02 per GiB per month.</li> <li>The first 250 GiB is included in the $5/month Spaces subscription (across all buckets).<ul> <li>This threshold has already been exceeded.</li> </ul> </li> <li>Additional usage is billed at $0.02/GiB/month.</li> </ul> <p>Data Transfer:</p> <ul> <li>Inbound (upload): Free</li> <li>Outbound (download):<ul> <li>The first 1 TB/month is included in the subscription (across all buckets).</li> <li>Usage exceeding this is billed at $0.01/GiB per month.</li> </ul> </li> </ul> <p>CDN (Optional):</p> <ul> <li>CDN can be enabled per bucket at no additional cost.</li> <li>Offers performance improvements for distributed clients and may help reduce backend bandwidth costs.</li> </ul>"},{"location":"devops/migration/#usersystem-access-to-do-spaces","title":"User/System Access to DO Spaces","text":""},{"location":"devops/migration/#access-control-options","title":"Access Control Options","text":""},{"location":"devops/migration/#digitalocean-console-access","title":"DigitalOcean Console Access","text":"<p>Question: Should TNGAP users be granted access to the DigitalOcean web console?</p> <ul> <li>If yes, users must be added to the appropriate DO Team by an administrator.</li> <li>Users with sufficient permissions can generate their own access keys if needed.</li> <li>Note that fine-grained IAM is not supported. DigitalOcean Teams only offer predefined roles: <p>DigitalOcean Teams currently do not support custom team roles. They offer a set of six predefined roles: Owner, Biller, Billing Viewer, Member, Modifier, and Resource Viewer.</p> </li> </ul>"},{"location":"devops/migration/#programmatic-access","title":"Programmatic Access","text":"<p>Managed through:</p> <ul> <li>Access keys (Access Key ID and Secret Access Key).</li> <li>Bucket-level policies configured via Terraform or the DO API.</li> </ul> <p>There is no equivalent IAM system as seen in Minio. Access key lifecycle must be handled manually or via external automation.</p>"},{"location":"devops/migration/#migration-of-iam-users-from-minio","title":"Migration of IAM Users from MinIO","text":"<ul> <li>DigitalOcean does not natively support MinIO-style IAM user/group constructs.</li> </ul> <p>Recommended Approach:</p> <ul> <li>Identify key service accounts and human users.</li> <li>Provision separate access keys for each service or integration.</li> <li>Use <code>digitalocean_spaces_bucket_policy</code> to apply principle of least privilege where applicable.</li> </ul>"},{"location":"devops/migration/#references","title":"References","text":"<ul> <li>Terraform: <code>digitalocean_spaces_bucket_policy</code> </li> <li>DigitalOcean Spaces Pricing</li> </ul>"},{"location":"user/","title":"TomorrowNow - Global Access Platform (GAP)","text":""},{"location":"user/#user-documentation","title":"User documentation","text":"<p>This is the homepage for all user related documentation.</p> <p>The user content is divided into three sections:</p> <ul> <li> <p>The quickstart tutorial, which aims to get you familiar with the basics of platform in around 5 minutes.</p> </li> <li> <p>The user guide, which describes common workflows in a tutorial format.</p> </li> <li> <p>The user manual, which describes each page of the user interface and what the various options on that page do.</p> </li> </ul>"},{"location":"user/guide/","title":"TomorrowNow - Global Access Platform (GAP)","text":""},{"location":"user/guide/#user-guide","title":"User guide","text":""},{"location":"user/manual/","title":"TomorrowNow - Global Access Platform (GAP)","text":""},{"location":"user/manual/#user-manual","title":"User manual","text":"<p>This section of the documentation describes every page in the application and what the various components of that page do. The manual is intended to function as a reference for the application. For narrative / workflow based tutorials, you may prefer to work through our user guide.</p>"},{"location":"user/quickstart/","title":"TomorrowNow - Global Access Platform (GAP)","text":""},{"location":"user/quickstart/#quickstart","title":"Quickstart","text":""},{"location":"user/quickstart/#installing-the-product","title":"Installing the product","text":""},{"location":"user/quickstart/#getting-started","title":"Getting started","text":""},{"location":"user/quickstart/#releases","title":"Releases","text":"<p>GitHub releases page Releases page</p>"}]}